
% Dataset recap.
We introduce \datasetfull{}: 2050 human-human, situated navigation dialogs in a photorealistic, simulated environment.
The dialogs contain complex phenomena that require egocentric visual grounding and referring to both dialog history and past navigation history for context.
\dataset{} is a valuable resource for studying \textit{in-situ} navigation interactions, and for training agents that both navigate human environments and ask questions when unsure, as well as those that provide verbal assistance to humans navigating in unfamiliar places.

% Task recap.
We then define the \taskfull{} task.
Our evaluations show that dialog history is relevant for navigation agents to learn a mapping between dialog-based instructions and correct navigation actions.
Further, we find that using a mixed form of both human and planner supervision combines the best of each: long-range exploration of an environment according to human intuition to find the goal, and short-range accuracy aligned with language input.

% Ways dataset falls short.
\paragraph{Limitations.}
The \dataset{} dataset builds on the Room-to-Room task in the MatterPort Simulator~\cite{anderson:cvpr18}.
We would like to use \dataset{} to train real world agents for dialog and navigation.
Simply fine-tuning on real world data may not be sufficient.
Real-world robot navigation relies on laser scan depths, not just RGB information, and invokes lower quality egocentric vision, sensor noise, and localization issues.
While the simulation provides photorealistic environments, it suffers from discrete, graph-based navigation, requiring a real world navigable environment to be mapped and divided into topological waypoints.
Human-human dialogs collected in high-fidelity, continuous motion simulators (e.g.,~\cite{ai2thor}) or using virtual reality technology may facilitate easier transfer to physical robot platforms.
However, sharing a simulation environment with the existing R2R task means that models for dialog history tasks like \task{} may benefit from pretraining on R2R.

\paragraph{Future Work.}
% Our model is very simple: what are some modeling extensions we think are reasonable to try?
The sequence-to-sequence model used in our experiments serves as an initial learning baseline for the \task{} task.
Moving forward, by formulating \task{} as a sequential decision process we can use RL to shape the agent's policy, as in recent VLN work~\cite{tan:naacl19}.
Dialog analysis also suggests that there is relevant information in the historical navigation actions which are not considered by the initial model.
Jointly conditioning dialog and navigation history may help resolve past reference instructions like ``Go back to the stairwell and go up one flight of steps,'' and could involve cross-modal attention alignment.

% Ways dataset can be built on further.
The \dataset{} dataset also provides a scaffold for navigation-centered question asking and question answering tasks.
In our future work, we will explore training two agents in tandem: one to navigate and ask questions when lost, and another to answer those questions.
This will facilitate end-to-end evaluation on \dataset{}, and will differ from all existing VLN tasks by involving two, trained agents engaged in task-oriented dialog.
