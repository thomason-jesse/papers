@inproceedings{stoia:lrec08,
  title={{SCARE: a Situated Corpus with Annotated Referring Expressions}},
  author={Stoia, Laura and Shockley, Darla Magdalena and Byron, Donna K and Fosler-Lussier, Eric},
  booktitle={LREC},
  year={2008}
}

@article{anderson:ls91,
  title={{The HCRC Map Task Corpus}},
  author={Anderson, A., and Bader, M., and Bard, E., and Boyle, and E., Doherty, G. M., and Garrod, S., and Isard, S., and Kowtko, J., and McAllister, J., and Miller, J., and Sotillo, C., and Thompson, H. S., and Weinert, R.},
  journal={Language and Speech},
  volume={34},
  pages={351--366},
  year={1991},
}

@inproceedings{nguyen:emnlp19,
  author = {Nguyen, Khanh and Daum{\'e} III, Hal},
  title = {{Help, Anna! Visual Navigation with Natural Multimodal Assistance via Retrospective Curiosity-Encouraging Imitation Learning}},
  booktitle = {EMNLP},
  year = {2019},
}

@article{devries:arxiv18,
  title={Talk the walk: Navigating new york city through grounded dialogue},
  author={de Vries, Harm and Shuster, Kurt and Batra, Dhruv and Parikh, Devi and Weston, Jason and Kiela, Douwe},
  journal={arXiv},
  year={2018}
}

@inproceedings{tan:naacl19,
  title={Learning to navigate unseen environments: Back translation with environmental dropout},
  author={Tan, Hao and Yu, Licheng and Bansal, Mohit},
  booktitle={NAACL},
  year={2019}
}

@inproceedings{marge:naacl19,
  title={A Research Platform for Multi-Robot Dialogue with Humans},
  author={Marge, Matthew and Nogar, Stephen and Hayes, Cory and Lukin, Stephanie and Bloecker, Jesse and Holder, Eric and Voss, Clare},
  booktitle={NAACL},
  year={2019}
}

@article{williams:auro19,
  title={Dempster-shafer theoretic resolution of referential ambiguity},
  author={Williams, Tom and Yazdani, Fereshta and Suresh, Prasanth and Scheutz, Matthias and Beetz, Michael},
  journal={Autonomous Robots},
  volume={43},
  number={2},
  pages={389--414},
  year={2019},
  publisher={Springer}
}

@inproceedings{murnane:siggraph19,
  title={Learning from Human-Robot Interactions in Modeled Scenes},
  author={Mark Murnane and Max Breitmeyer and Francis Ferraro and Cynthia Matuszek and Don Engel},
  booktitle={SIGGRAPH},
  year={2019}
}

@inproceedings{thomason:icra19,
  title={Improving Grounded Natural Language Understanding through Human-Robot Dialog},
  author={Jesse Thomason and Aishwarya Padmakumar and Jivko Sinapov and Nick Walker and Yuqian Jiang and Harel Yedidsion and Justin Hart and Peter Stone and Raymond J. Mooney},
  booktitle={ICRA},
  year={2019}
}

@inproceedings{he:cvpr16,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={CVPR},
  year={2016}
}

@article{ai2thor,
    Author = {Eric Kolve and Roozbeh Mottaghi and Winson Han and Eli VanderBilt and Luca Weihs and Alvaro Herrasti and
Daniel Gordon and Yuke Zhu and Abhinav Gupta and Ali Farhadi},
    Title = {{AI2-THOR: An Interactive 3D Environment for Visual AI}},
    Journal = {arXiv},
    Year = {2017}
}

@article{jain:acl19,
  title={Stay on the Path: Instruction Fidelity in Vision-and-Language Navigation},
  author={Jain, Vihan and Magalhaes, Gabriel and Ku, Alex and Vaswani, Ashish and Ie, Eugene and Baldridge, Jason},
  journal={ACL},
  year={2019}
}

@inproceedings{thomason:naacl19,
  title={{Shifting the Baseline: Single Modality Performance on Visual Navigation \& QA}},
  author={Jesse Thomason and Daniel Gordon and Yonatan Bisk},
  booktitle={NAACL},
  year={2019}
}

@inproceedings{vogel:acl10,
  title={Learning to follow navigational directions},
  author={Vogel, Adam and Jurafsky, Dan},
  booktitle={Association for Computational Linguistics (ACL)},
  year={2010},
}

@inproceedings{zellers:cvpr19,
  title={From recognition to cognition: Visual commonsense reasoning},
  author={Zellers, Rowan and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
  booktitle={CVPR},
  year={2019}
}

@article{hudson:cvpr18,
    title={{GQA}: A New Dataset for Real-World Visual Reasoning 
    and Compositional Question Answering},
    author={Hudson, Drew A and Manning, Christopher D},
    journal={CVPR},
    year={2019}
}

@inproceedings{kottur:naacl19,
  title={{CLEVR-Dialog}: A Diagnostic Dataset for Multi-Round Reasoning in Visual Dialog},
  author={Kottur, Satwik and Moura, Jos{\'e} MF and Parikh, Devi and Batra, Dhruv and Rohrbach, Marcus},
  booktitle={NAACL},
  year={2019}
}

@inproceedings{johnson:cvpr17,
  title={{CLEVR}: A diagnostic dataset for compositional language and elementary visual reasoning},
  author={Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens and Fei-Fei, Li and Lawrence Zitnick, C and Girshick, Ross},
  booktitle={CVPR},
  year={2017}
}

@inproceedings{rajpurkar:emnlp16,
  title={{SQuAD}: 100,000+ Questions for Machine Comprehension of Text},
  author={Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
  booktitle={EMNLP},
  year={2016}
}

@inproceedings{saeidi:emnlp18,
  title={Interpretation of Natural Language Rules in Conversational Machine Reading},
  author={Saeidi, Marzieh and Bartolo, Max and Lewis, Patrick and Singh, Sameer and Rockt{\"a}schel, Tim and Sheldon, Mike and Bouchard, Guillaume and Riedel, Sebastian},
  booktitle={EMNLP},
  year={2018}
}

@article{reddy:tacl19,
  title={{CoQa}: A conversational question answering challenge},
  author={Reddy, Siva and Chen, Danqi and Manning, Christopher D},
  journal={TACL},
  volume={7},
  year={2019},
  publisher={MIT Press}
}

@inproceedings{chen:cvpr19,
  title={Touchdown: Natural language navigation and spatial reasoning in visual street environments},
  author={Chen, Howard and Suhr, Alane and Misra, Dipendra and Snavely, Noah and Artzi, Yoav},
  booktitle={CVPR},
  year={2019}
}

@InProceedings{chen:acl12,
  title = "Fast Online Lexicon Learning for Grounded Language Acquisition",
  author = "David L. Chen",
  booktitle = "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL-2012)",
  address = "Jeju, Republic of Korea",
  month = "July",
  year = 2012
} 

@inproceedings{macmahon:aaai06,
  title = "Walk the Talk: Connecting Language, Knowledge, and Action in Route Instructions",
  author = "Matt MacMahon and Brian Stankiewicz and Benjamin Kuipers",
  booktitle = "AAAI",
  year = 2006
} 

@inproceedings{das:cvpr17,
  title={{V}isual {D}ialog},
  author={Abhishek Das and Satwik Kottur and Khushi Gupta and Avi Singh and Deshraj Yadav and Jos\'e M.F. Moura and
    Devi Parikh and Dhruv Batra},
  booktitle={CVPR},
  year={2017}
}

@inproceedings{antol:iccv15, 
author = {Stanislaw Antol and Aishwarya Agrawal and Jiasen Lu and Margaret Mitchell and Dhruv Batra and C. Lawrence Zitnick and Devi Parikh}, 
title = {{VQA}: {V}isual {Q}uestion {A}nswering}, 
booktitle = {ICCV}, 
year = {2015}, 
}

@article{Turing:Mind1950,
  title = {Computing machinery and intelligence},
  author = {Alan M. Turing},
  year = {1950},
  journal = {Mind},
  pages = {433--460},
  publisher = {Thomas Nelson and Son, Ltd.},
}

@article{Godel:1940,
  title = {The Consistency of the Axiom of Choice and of the Generalized Continuum Hypothesis with the Axioms of Set Theory},
  author = {Kurt G\"{o}del},
  year = {1940},
  publisher = {Princeton University Press},
}

@article{schutze:cl98,
  author = "Hinrich Schutze",
  title = "Automatic Word Sense Discrimination",
  journal = "Computational Linguistics",
  volume = "24",
  number = "1",
  pages = "97--123",
  year = "1998",
}

@InProceedings{yarowsky:acl95,
  title =        "Unsupervised Word Sense Disambiguation Rivaling Supervised Methods",
  author =       "David Yarowsky",
  booktitle =    "ACL95",
  year =         "1995",
  pages =        "189--196",
}

@article{young:ieee13,
  title={{POMDP}-based statistical spoken dialog systems: A review},
  author={Young, Steve and Ga{\v{s}}i{\'c}, Milica and Thomson, Blaise and Williams, Jason D},
  journal={Proceedings of the IEEE},
  volume={101},
  number={5},
  pages={1160--1179},
  year={2013},
  publisher={IEEE}
}

@Book{fellbaum:book98,
  author =       "Christiane D. Fellbaum",
  title =        "{WordNet}: An Electronic Lexical Database",
  publisher =    "MITP",
  address =      "Cambridge, MA",
  year =         "1998",
}

@Article{barnard:aij05,
  author = "Kobus Barnard and Matthew Johnson",
  title = "Word sense disambiguation with pictures",
  journal = "Artificial Intelligence",
  volume = "167",
  pages = "13--30",
  year = "2005"
}

@inproceedings{thomason:ijcai15,
  author = {Thomason, Jesse and Zhang, Shiqi and Mooney, Raymond and Stone, Peter},
  title = {Learning to Interpret Natural Language Commands through Human-Robot Dialog},
  booktitle = {Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI)},
  pages = {1923-1929},
  location = {Buenos Aires, Argentina},
  month = {July},
  year = {2015}
}

@inproceedings{thomason:ijcai16,
  author = {Thomason, Jesse and Sinapov, Jivko and Svetlik, Maxwell and Stone, Peter and Mooney, Raymond},
  title = {Learning Multi-Modal Grounded Linguistic Semantics by Playing ``{I} Spy''},
  booktitle = {Proceedings of the 25th International Joint Conference on Artificial Intelligence (IJCAI)},
  pages = {3477-3483},
  location = {New York City, New York},
  month = {July},
  year = {2016}
}

@inproceedings{thomason:ijcai17,
  title = {Multi-Modal Word Synset Induction},
  author = {Jesse Thomason and Raymond J. Mooney},
  booktitle = {Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI-17)},
  pages = {4116-4122},
  location = {Melbourne, Australia},
  month = {August},
  year = {2017}
}

@inproceedings{matuszek:icml12,
  title = "A Joint Model of Language and Perception for Grounded Attribute Learning",
  author = "Cynthia Matuszek and Nicholas FitzGerald and Luke Zettlemoyer and Liefeng Bo and Dieter Fox",
  booktitle = "Proceedings of the 29th International Conference on Machine Learning",
  address = "Edinburgh, Scotland, UK",
  year = "2012"
}

@inproceedings{kollar:rss13,
  author = {Kollar, Thomas and Krishnamurthy, Jayant and Strimel, Grant},
  title = {Toward Interactive Grounded Language Acquisition},
  booktitle = {Robotics: Science and Systems},
  year = {2013}
}

@article{krishnamurthy:acl13,
  title={Jointly Learning to Parse and Perceive: Connecting Natural Language to the Physical World},
  author={Krishnamurthy, Jayant and Kollar, Thomas},
  journal={Transactions of the Association for Computational Linguistics},
  volume={1},
  pages={193--206},
  year={2013}
}

@inproceedings{dindo:iros10,
  title = "A Probabilistic Approach to Learning a Visually Grounded Language Model through Human-Robot Interaction",
  author = "Haris Dindo and Daniele Zambuto",
  booktitle = "International Conference on Intelligent Robots and Systems",
  publisher = "IEEE",
  pages = "760-796",
  address = "Taipei, Taiwan",
  year = "2010"
}

@inproceedings{sun:icra13,
  title = "Attribute Based Object Identification",
  author = "Yuyin Sun and Liefeng Bo and Dieter Fox",
  booktitle = "International Conference on Robotics and Automation",
  publisher = "IEEE",
  pages = "2096-2103",
  address = "Karlsruhe, Germany",
  year = "2013"
}

@inproceedings{parde:ijcai15,
  title = "Grounding the Meaning of Words through Vision and Interactive Gameplay",
  author = "Natalie Parde and Adam Hair and Michalis Papakostas and Konstantinos Tsiakas and Maria Dagioglou and Vangelis Karkaletsis and Rodney D. Nielsen",
  booktitle = "Proceedings of the 24th International Joint Conference on Artificial Intelligence",
  pages = "1895-1901",
  address = "Buenos Aires, Argentina",
  year = "2015"
}

@inproceedings{perera:aaai13,
  title = "SALL-E: Situated Agent for Language Learning",
  author = "Ian Perera and James F. Allen",
  booktitle = "Proceedings of the 27th AAAI Conference on Artificial Intelligence",
  pages = "1241-1247",
  address = "Bellevue, Washington, USA",
  year = "2013"
}

@inproceedings{liu:acl14,
  title = "Probabilistic Labeling for Efficient Referential Grounding based on Collaborative Discourse",
  author = "Changson Liu and Lanbo She and Rui Fang and Joyce Y. Chai",
  booktitle = "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics",
  pages = "13-18",
  address = "Baltimore, Maryland, USA",
  year = "2014"
}

@inproceedings{malinowski:nips14,
  title = "A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input",
  author = "Mateusz Malinowski and Mario Fritz",
  booktitle = "Proceedings of the 28th Annual Conference on Neural Information Processing Systems",
  pages = "13-18",
  address = "Montr\'{e}al, Canada",
  year = "2014"
}

@inproceedings{matuszek:aaai14,
  title = "Learning from Unscripted Deictic Gesture and Language for Human-Robot Interactions",
  author = "Cynthia Matuszek and Liefeng Bo and Luke Zettlemoyer and Dieter Fox",
  booktitle = "Proceedings of the 28th AAAI Conference on Artificial Intelligence",
  address = "Queb\'{e}c City, Queb\'{e}c, Canada",
  year = "2014"
}

@inproceedings{mohan:acs13,
  title = "Towards an Indexical Model of Situated Language Comprehension for Real-World Cognitive Agents",
  author = "Shiwali Mohan and Aaron H. Mininger and John E. Laird",
  booktitle = "Proceedings of the 2nd Annual Conference on Advances in Cognitive Systems",
  address = "Baltimore, Maryland, USA",
  year = "2013"
}

@inproceedings{spranger:ijcai15,
  title = "Co-Acquisition of Syntax and Semantics---An Investigation of Spatial Language",
  author = "Michael Spranger and Luc Steels",
  booktitle = "Proceedings of the 24th International Joint Conference on Artificial Intelligence",
  pages = "1909-1915",
  address = "Buenos Aires, Argentina",
  year = "2015"
}

@inproceedings{kiela:emnlp15,
  title = "Multi- and Cross-Modal Semantics Beyond Vision: Grounding in Auditory Perception",
  author = "Douwe Kiela and Stephen Clark",
  booktitle = "Proceedings of the 2015 Conference on Emperical Methods in Natural Language Processing",
  address = "Lisbon, Portugal",
  pages = "2461-2470",
  year = "2015"
}

@inproceedings{sinapov:icra14,
  title = "Learning relational object categories using behavioral exploration and multimodal perception",
  author = "Jivko Sinapov and Connor Schenck and Alexander Stoytchev",
  booktitle = "IEEE International Conference on Robotics and Automation (ICRA)",
  year = "2014"
}

@inproceedings{vogel:aaai10,
  title = "Eye Spy: Improving Vision through Dialog",
  author = "Adam Vogel and Karthik Raghunathan and Dan Jurafsky",
  booktitle = "Association for the Advancement of Artificial Intelligence",
  pages = "175-176",
  year = "2010"
}

@inproceedings{rusu:icra09,
  title={Fast point feature histograms (FPFH) for 3D registration},
  author={Rusu, Radu Bogdan and Blodow, Nico and Beetz, Michael},
  booktitle={Robotics and Automation, 2009. ICRA'09. IEEE International Conference on},
  pages={3212--3217},
  year={2009},
  organization={IEEE}
}

@article{simonyan:corr14,
  author = "Simonyan, Karen and Zisserman, Andrew",
  title = "Very Deep Convolutional Networks for Large-Scale Image Recognition",
  journal = "CoRR",
  volume = "abs/1409.1556",
  year = "2014"
}

The classic Tellex+Knepper paper. Uses G3 graphs to perform "inverse semantics", generating a beam of language requests that might lead a human helper to recover a robot from failure (e.g. not being able to reach a table leg needed for assembly), then re-ranking those requests based on the G3 model of how humans might ground them (to remove ambiguous requests and favor targeted onces). Identifies some areas for future work, such as generating requests at different help levels (unskilled user versus more expensive request for an experienced user/operator). Grounding is done by pre-training factors in the G3 model for constituent/word correspondences with real-world objects from counts in a corpus of labeled demonstration videos, with language labels drawn from Mechanical Turk.
@inproceedings{tellex:rss14,
  author = "Stefanie Tellex and Ross Knepper and Adrian Li and Daniela Rus and Nicholas Roy",
  title = "Asking for Help Using Inverse Semantics",
  booktitle = "RSS",
  year = "2014"
}

@inproceedings{walter:rss13,
  author = "Matthew Walter and Sachithra Hemachandra and Bianca Homberg and Stefanie Tellex and Seth Teller",
  title = "Learning Semantic Maps from Natural Language Descriptions",
  booktitle = "Proceedings of Robotics: Science and Systems (RSS)",
  address = "Berlin, Germany",
  year = "2013"
}

@article{sinapov:ras14,
  title={Grounding semantic categories in behavioral interactions: Experiments with 100 objects},
  author={Sinapov, Jivko and Schenck, Connor and Staley, Kerrick and Sukhoy, Vladimir and Stoytchev, Alexander},
  journal={Robotics and Autonomous Systems},
  volume={62},
  number={5},
  pages={632--645},
  year={2014},
  publisher={Elsevier}
}

@article{aldoma:ram12,
  title={Point cloud library},
  author={Aldoma, Aitor and Marton, Zoltan-Csaba and Tombari, Federico and Wohlkinger, Walter and Potthast, Christian and Zeisl, Bernhard and Rusu, Radu Bogdan and Gedikli, Suat and Vincze, Markus},
  journal={IEEE Robotics \& Automation Magazine},
  volume={1070},
  number={9932/12},
  year={2012}
}

@inproceedings{deng:cvpr09,
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li,  Li-Jia and Li, Kai and Fei-Fei, Li},
  title={{ImageNet: A Large-Scale Hierarchical Image Database}},
  booktitle={Computer Vision and Pattern Recognition},
  year={2009}
}

@inproceedings{manandhar:acl10,
  author = {Manandhar, Suresh and Klapaftis, Ioannis P. and Dligach, Dmitriy and Pradhan, Sameer S.},
  title = {SemEval-2010 Task 14: Word Sense Induction \& Disambiguation},
  booktitle = {Proceedings of the 5th International Workshop on Semantic Evaluation},
  series = {SemEval '10},
  year = {2010},
  location = {Los Angeles, California},
  pages = {63--68},
  numpages = {6},
  publisher = {Association for Computational Linguistics},
  address = {Stroudsburg, PA, USA},
}

@article{dimarco:cl13,
  title={Clustering and Diversifying Web Search Results with Graph-Based Word Sense Induction},
  author={Di Marco, Antonio and Navigli, Roberto},
  journal={Computational Linguistics},
  volume={39},
  number={3},
  pages={709--754},
  year={2013},
  publisher={Association for Computational Linguistics}
}

@article{tibshirani:jrssbsm01,
  title={Estimating the number of clusters in a data set via the gap statistic},
  author={Tibshirani, Robert and Walther, Guenther and Hastie, Trevor},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={63},
  number={2},
  pages={411--423},
  year={2001},
  publisher={Wiley Online Library}
}

@incollection{lucchi:eccv12,
  title={Joint image and word sense discrimination for image retrieval},
  author={Lucchi, Aurelien and Weston, Jason},
  booktitle={Computer Vision--ECCV},
  pages={130--143},
  year={2012},
  publisher={Springer}
}

@article{navigli:csur09,
  title={Word sense disambiguation: A survey},
  author={Navigli, Roberto},
  journal={ACM Computing Surveys (CSUR)},
  volume={41},
  number={2},
  pages={10},
  year={2009},
  publisher={ACM}
}

@inproceedings{pedersen:emnlp97,
  title={Distinguishing word senses in untagged text},
  author={Pedersen, Ted and Bruce, Rebecca},
  booktitle = {Proceedings of the Second Conference on Empirical Methods in Natural Language},
  year = {1997},
  location = {Providence, RI},
  pages = {197--207},
}

@inproceedings{bordag:eacl06,
  title={Word sense induction: Triplet-based clusering and automatic evaluation.},
  author={Bordag, Stefan},
  booktitle = {Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics},
  year = {2006},
  location = {Trento, Italy},
  pages = {137--144},
}

@inproceedings{bordes:ais10,
  title={Towards understanding situated natural language},
  author={Bordes, Antoine and Usunier, Nicolas and Collobert, Ronan and Weston, Jason},
  booktitle={13th International Conference on Artificial Intelligence and Statistics},
  volume={9},
  pages={65--72},
  year={2010}
}

@inproceedings{saenko:nips09,
  title={Filtering abstract senses from image search results},
  author={Saenko, Kate and Darrell, Trevor},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1589--1597},
  year={2009}
}

@inproceedings{reisinger:naacl10,
  title={Multi-Prototype Vector-Space Models of Word Meaning},
  author={Joseph Reisinger and Raymond J. Mooney},
  booktitle={Proceedings of Human Language Technologies: The Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT-10)},
  pages={109-117},
  year={2010}
}

@inproceedings{sinapov:ijcai16,
  title={Learning to Order Objects using Haptic and Proprioceptive Exploratory Behaviors},
  author={Jivko Sinapov and Priyanka Khante and Maxwell Svetlik and Peter Stone},
  booktitle={Proceedings of the 25th International Joint Conference on Artificial Intelligence (IJCAI)},
  location={New York},
  year={2016}
}

@inproceedings{fang:aaai14,
  title={Collaborative Models for Referring Expression Generation towards Situated Dialogue},
  author={Rui Fang and Malcolm Doering and Joyce Y. Chai},
  booktitle={Proceedings of the 28th AAAI Conference on Artificial Intelligence},
  pages={1544-1550},
  year={2014}
}

@inproceedings{liu:icdm03,
  title={Building Text Classifiers Using Positive and Unlabeled Examples},
  author={Bing Liu and Yang Dai and Xiaoli Li and Wee Sun Lee and Philip Yu},
  booktitle={Proceedings of the Third IEEE International Conference on Data Mining (ICDM-03)},
  location={Melbourne, Florida},
  year={2003}
}

@inproceedings{thomason:aied13,
  author = {Thomason, Jesse and Nguyen, Huy and Litman, Diane},
  title = {Prosodic Entrainment and Tutoring Dialogue Success},
  booktitle = {Proceedings of the 16th International Conference on Artificial Intelligence in Education (AIED)},
  pages = {750-753},
  location = {Memphis, TN},
  month = {July},
  year = {2013}
}

@inproceedings{loeff:coling06,
  author = {Loeff, Nicolas and Alm, Cecilia Ovesdotter and Forsyth, David A.},
  title = {Discriminating Image Senses by Clustering with Multimodal Features},
  booktitle = {Proceedings of the COLING/ACL on Main Conference Poster Sessions},
  series = {COLING-ACL '06},
  year = {2006},
  location = {Sydney, Australia},
  pages = {547--554},
  numpages = {8},
  acmid = {1273144},
  publisher = {Association for Computational Linguistics},
  address = {Stroudsburg, PA, USA},
} 

@inproceedings{chen:cvpr15,
  Author = {Xinlei Chen and Alan Ritter and Abhinav Gupta and Tom Mitchell},
  Title = {{S}ense {D}iscovery via {C}o-{C}lustering on {I}mages and {T}ext},
  Booktitle = {Computer Vision and Pattern Recognition (CVPR)},
  Year = 2015,
}

@inproceedings{rosenberg:emnlp07,
  author = {Rosenberg, Andrew and Hirschberg, Julia},
  booktitle = {{Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)}},
  pages = {410--420},
  title = {{V-Measure: A Conditional Entropy-Based External Cluster Evaluation Measure}},
  year = {2007}
}

@incollection{saenko:nips08, 
  Author = {Kate Saenko and Trevor Darrell}, 
  Booktitle = {Advances in Neural Information Processing Systems 21}, 
  Title = {Unsupervised Learning of Visual Sense Models for Polysemous Words}, 
  Editor = {D. Koller and D. Schuurmans and Y. Bengio and L. Bottou}, 
  Year = {2008}, 
  Pages = {1393--1400}
}

@incollection{cheng:ieee95, 
  Author = {Yizong Cheng}, 
  Booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  Volume = {17},
  Number = {8},
  Title = {Mean Shift, Mode Seeking, and Clustering}, 
  Year = {1995}, 
  Pages = {790--799} 
}

@Article{lakin:jnb03,
author="Lakin, Jessica L. and Jefferis, Valerie E. and Cheng, Clara Michelle and Chartrand, Tanya L.",
title="The Chameleon Effect as Social Glue: Evidence for the Evolutionary Significance of Nonconscious Mimicry",
journal="Journal of Nonverbal Behavior",
year="2003",
volume="27",
number="3",
pages="145--162",
issn="1573-3653",
doi="10.1023/A:1025389814290"
}

@inproceedings{gravano:isca15,
  author={Gravano, Agust{\i}n and Benu{\v{s}}, {\v{S}}tefan and Levitan, Rivka and Hirschberg, Julia},
  title={Backward mimicry and forward influence in prosodic contour choice in Standard American English},
  booktitle={Sixteenth Annual Conference of the International Speech Communication Association},
  year={2015}
}

@inproceedings{lubold:cscl15,
  author={Lubold, Nichola and Walker, Erin and Pon-Barry, Heather},
  title={Relating Entrainment, Grounding, and Topic of Discussion in Collaborative Learning Dialogues},
  booktitle={Proceedings of the 11th International Conference on Computer Supported Collaborative Learning (CSCL)},
  year={2015}
}

@inproceedings{mericli:aamas14,
 author = {Meri\c{c}li, {\c{C}}etin and Klee, Steven D. and Paparian, Jack and Veloso, Manuela},
 title = {An Interactive Approach for Situated Task Specification Through Verbal Instructions},
 booktitle = {Proceedings of the 2014 International Conference on Autonomous Agents and Multi-agent Systems (AAMAS)},
 year = {2014},
 location = {Paris, France},
 pages = {1069--1076},
}

@incollection{steedman:nts11,
  Author = {Mark Steedman and Jason Baldridge},
  Title = {Combinatory categorial grammar},
  Editor = {Robert Borsley and Kersti Borjars},
  Booktitle = {Non-Transformational Syntax: Formal and Explicit Models of Grammar},
  Publisher = {Wiley-Blackwell},
  Year = {2011}
}

@article{liang:arl15,
  author = {Liang, Percy and Potts, Cristopher},
  title = {Bringing machine learning and compositional semantics together},
  journal = {Annual Review of Linguistics},
  year = {2015},
  volume = {1},
  number = {1},
  pages = {355--376}
}

@inproceedings{kwaitkowski:emnlp13,
  title={Scaling Semantic Parsers with On-the-fly Ontology Matching},
  author={Kwiatkowski, Tom and Choi, Eunsol and Artzi, Yoav and Zettlemoyer, Luke},
  booktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year=2013,
  pages={1545--1556}
}

@inproceedings{liang:acl11,
  author = {P. Liang and M. I. Jordan and D. Klein},
  booktitle = {Association for Computational Linguistics (ACL)},
  pages = {590--599},
  title = {Learning Dependency-Based Compositional Semantics},
  year = {2011},
}

@inproceedings{berant:emnlp13,
  author = {J. Berant and A. Chou and R. Frostig and P. Liang},
  booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
  title = {Semantic Parsing on {F}reebase from Question-Answer Pairs},
  year = {2013},
}

@inproceedings{artzi:emnlp11,
 author = {Artzi, Yoav and Zettlemoyer, Luke},
 title = {Bootstrapping Semantic Parsers from Conversations},
 booktitle = {Proceedings of the Conference on Empirical Methods in Natural Language Processing},
 year = {2011},
 location = {Edinburgh, United Kingdom},
 pages = {421--432},
 publisher = {Association for Computational Linguistics},
 address = {Stroudsburg, PA, USA},
} 

@inproceedings{williams:aaai15,
  author = {Tom Williams and Gordon Briggs and Brad Oosterveld and Matthias Scheutz},
  title = {Going Beyond Command- Based Instructions: Extending Robotic Natural Language Interaction Capabilities},
  booktitle = {Proceedings of AAAI},
  year = {2015},
}

@inproceedings{dukes:semeval14,
  title={Semeval-2014 task 6: Supervised semantic parsing of robotic spatial commands},
  author={Dukes, Kais},
  booktitle={Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval)},
  pages={45--53},
  year={2014},
}

@inproceedings{matuszek:iser12,
  title={Learning to Parse Natural Language Commands to a Robot Control System},
  author={Cynthia Matuszek and Evan Herbst and Luke Zettlemoyer and Dieter Fox},
  booktitle={International Symposium on Experimental Robotics (ISER)},
  year={2012},
}

@inproceedings{kollar:hri10,
 author = {Kollar, Thomas and Tellex, Stefanie and Roy, Deb and Roy, Nicholas},
 title = {Toward Understanding Natural Language Directions},
 booktitle = {Proceedings of the 5th ACM/IEEE International Conference on Human-robot Interaction},
 series = {HRI '10},
 year = {2010},
 location = {Osaka, Japan},
 pages = {259--266},
}

@inproceedings{mei:aaai16,
  title     = {Listen, Attend, and Walk: Neural Mapping of Navigational Instructions to Action Sequences},
  author    = {Hongyuan Mei and Mohit Bansal and Matthew R. Walter},
  booktitle = {Proceedings of AAAI},
  year      = {2016}
}

@inproceedings{misra:rss14,
 author = {Dipendra K Misra and Jaeyong Sung and Kevin Lee and Ashutosh Saxena},
 title = {Tell Me Dave: Context-Sensitive Grounding of Natural Language to Mobile Manipulation Instructions},
 booktitle = {Robotics: Science and Systems},
 series = {RSS},
 year = {2014}
}

@article{artzi:tacl13,
  title={Weakly Supervised Learning of Semantic Parsers for Mapping Instructions to Actions},
  author={Artzi, Yoav and Zettlemoyer, Luke},
  journal={Transactions of the Association for Computational Linguistics},
  volume={1},
  number={1},
  pages={49--62},
  year={2013},
  publisher={Association for Computational Linguistics}
}

@inproceedings{kuehne:cvpr14,
   author = {Kuehne, H. and Arslan, A. B. and Serre, T.},
   title = {The Language of Actions: Recovering the Syntax and Semantics of Goal-Directed Human Activities},
   booktitle = {Proceedings of Computer Vision and Pattern Recognition Conference (CVPR)},
   year = {2014}
}

@inproceedings{lu:robocup15,
 author = {Lu, Dongcai and Chen, Xiaoping},
 title = {Towards an Architecture Combining Grounding and Planning for Human-Robot Interaction},
 booktitle = {RoboCup},
 year = {2015},
 pages = {214--225}
} 

@inproceedings{she:sigdial14,
 author = {Lanbo She and Shaohua Yang and Yu Cheng and Yunyi Jia and Joyce Y. Chai and Ning Xi},
 title = {Back to the Blocks World: Learning New Actions through Situated Human-Robot Dialogue},
 booktitle = {Proceedings of 15th SIGDIAL Meeting on Discourse and Dialogue},
 location = {Philadelphia, Pennsylvania},
 year = {2014}
} 

@article{yang:acs14,
  title={A Cognitive System for Understanding Human Manipulation Actions},
  author={Yang, Yezhou and Ferm{\"u}ller, Cornelia and Aloimonos, Yiannis and Guha, Anupam},
  journal={Advances in Cognitive Systems},
  volume={3},
  pages={67--86},
  year={2014},
  publisher={the Cognitive Systems Foundation}
}

@inproceedings{liang:acl09,
  author = {P. Liang and M. I. Jordan and D. Klein},
  booktitle = {Association for Computational Linguistics and International Joint Conference on Natural Language Processing (ACL-IJCNLP)},
  pages = {91--99},
  title = {Learning Semantic Correspondences with Less Supervision},
  year = {2009}
}

@inproceedings{hu:cvpr16,
  title = {Natural Language Object Retrieval},
  author = {Hu, Ronghang and Xu, Huazhe and Rohrbach, Marcus and Feng, Jiashi and Saenko, Kate and Darrell, Trevor},
  year = {2016},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}
}

@inproceedings{lazaridou:acl14,
  title = {Is this a wampimuk? Cross-modal mapping between distributional semantics and the visual world.},
  author = {A. Lazaridou, E. Bruni and M. Baroni.},
  year = {2014},
  location = {East Stroudsburg, Pennsylvania},
  booktitle = {Proceedings of ACL 2014 (52nd Annual Meeting of the Association for Computational Linguistics)},
  pages = {1403--1414}
}

@InProceedings{fitzgerald:emnlp13,
  author    = {FitzGerald, Nicholas  and  Artzi, Yoav  and  Zettlemoyer, Luke},
  title     = {Learning Distributions over Logical Forms for Referring Expression Generation},
  booktitle = {Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing},
  month     = {October},
  year      = {2013},
  address   = {Seattle, Washington, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {1914--1925}
}

@InProceedings{silberer:emnlp12,
  author    = {Silberer, Carina  and  Lapata, Mirella},
  title     = {Grounded Models of Semantic Representation},
  booktitle = {Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning},
  month     = {July},
  year      = {2012},
  address   = {Jeju Island, Korea},
  publisher = {Association for Computational Linguistics},
  pages     = {1423--1433}
}

@Article{roy:cogsci02,
  author = {Deb Roy and Alex Pentland},
  title = {Learning words from sights and sounds: a computational model},
  journal = {COGSCI},
  year = {2002},
  number = {1},
  volume = {26},
  pages = {113--146}
}

@Article{harnad:phys90,
  author = {S. Harnad},
  title = {The Symbol Grounding Problem},
  journal = {Physica D},
  volume = {42},
  pages = {335--346},
  year = {1990}
}

@inproceedings{bastianelli:jssp13,
  title={Textual Inference and Meaning Representation in Human Robot Interaction},
  author={Bastianelli, Emanuele and Castellucci, Giuseppe and Croce, Danilo and Basili, Roberto},
  booktitle={Joint Symposium on Semantic Processing},
  year={2013},
  address={Trento, Italy}
}

@inproceedings{mohan:acs12,
  title={Acquiring grounded representations of words with situated interactive instruction},
  author={Mohan, Shiwali and Mininger, Aaron H and Kirk, James R and Laird, John E},
  booktitle={Advances in Cognitive Systems},
  year={2012}
}

@inproceedings{liu:aaai15,
  title={Learning to Mediate Perceptual Differences in Situated Human-Robot Dialogue},
  author={Liu, Changsong and Chai, Joyce Yue},
  booktitle={AAAI Conference on Artificial Intelligence (AAAI)},
  year={2015}
}

@InProceedings{krause:aaai14,
  title = {Learning to Recognize Novel Objects in One Shot through Human-Robot Interactions in Natural Language Dialogues},
  author = {Evan Krause and Michael Zillich and Thomas Williams and Matthias Scheutz},
  booktitle = {Proceedings of Twenty-Eighth AAAI Conference on Artificial Intelligence},
  year = {2014},
}

@misc{artzi:13spf,
    Author = {Yoav Artzi and Luke Zettlemoyer},
    Title = {{UW SPF: The University of Washington Semantic Parsing Framework}},
    Year = {2013},
    Eprint = {arXiv:1311.3011}
}

@inproceedings{quigley:icra09,
  title={{ROS}: an open-source Robot Operating System},
  author={Quigley, Morgan and Conley, Ken and Gerkey, Brian and Faust, Josh and Foote, Tully and Leibs, Jeremy and Wheeler, Rob and Ng, Andrew Y},
  booktitle={Open Source Software in Robotics Workshop at the IEEE International Conference on Robotics and Automation (ICRA)},
  @volume={3},
  @number={3.2},
  year={2009}
}

@inproceedings{lee:ijcai13,
  author = {Lee, Joohyung and Lifschitz, Vladimir and Yang, Fangkai},
  title={{Action Language $\mathcal{BC}$: A Preliminary Report}},
  booktitle={Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI)},
  year={2013}
}

@InProceedings{khandelwal:icaps14,
  author = {Khandelwal, Piyush and Yang, Fangkai and Leonetti, Matteo and Lifschitz, Vladimir and Stone, Peter},
  title = {{Planning in Action Language $\mathcal{BC}$ while Learning Action
  Costs for Mobile Robots}},
  booktitle = {Proceedings of the International Conference on Automated Planning and Scheduling (ICAPS)},
  @location = {Portsmouth, New Hampshire, USA},
  @month = {June},
  year = {2014}
}

@INPROCEEDINGS{whitney:icra16,
  author = {Whitney, David and Eldon, Miles and Oberlin, John and Tellex, Stefanie},
  title = {{Interpreting Multimodal Referring Expressions in Real Time}},
  booktitle = {{International Conference on Robotics and Automation}},
  year = {2016}
}

@InCollection{grice:bkchapter75,
  author =       "H. Paul Grice",
  title =        "Logic and Conversation",
  booktitle =    "Syntax and Semantics 3: Speech Acts",
  publisher =    "Academic Press",
  year =         "1975",
  editor =       "Peter Cole and Jerry Morgan",
  pages =        "41--58",
  address =      "New York",
}

@InCollection{lopes:icassp13,
  author = {Jos\'{e} Lopes and Maxine Eskenazi and Isabel Trancoso},
  title = {Automated Two-Way Entrainment to Improve Spoken Dialog System Performance},
  booktitle = {International Conference on Acoustics Speech and Signal Processing (ICASSP)},
  publisher = {IEEE},
  year = {2013}
}

@inproceedings{elkan:kdd08
  ,title     = "Learning Classifiers from Only Positive and Unlabeled Data"
  ,author    = "C. Elkan and K. Noto" 
  ,booktitle = "Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 2008)"
  ,pages     = "213--220"
  ,year      = "2008"
}

@inproceedings{chang:kdd16
  ,title     = "Positive-Unlabled Learning in Streaming Networks."
  ,author    = "Shiyu Chang and Yang Zhang and Jiliang Tang and Dawei Yin and Yi Chang and Mark A. Hasegawa-Johnson and Thomas S. Huang" 
  ,booktitle = "Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 2016)"
  ,year      = "2016"
}

@article{guadarrama:ijrr15,
author = {Sergio Guadarrama and Erik Rodner and Kate Saenko and Trevor Darrell},
journal = {International Journal of Robotics Research (IJRR)},
title = {Understanding Object Descriptions in Robotics by Open-vocabulary Object Retrieval and Detection},
number = {1-3},
volume = {35},
year = {2015},
pages = {265-280},
}

@InProceedings{resinger:naacl10,
  author = {Joseph Reisinger and Raymond J. Mooney},
  title = {Multi-Prototype Vector-Space Models of Word Meaning},
  booktitle = {Proceedings of the 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)},
  pages = {109--117},
  year = {2010}
}

A*-based parsing over forest of parses as hypergraphs. Gets state-of-the-art performance on CCG parsing benchmarks and is very fast. Uses local in-span context plus global information from bi-directional LSTM across leaves informing span tokens' representations.
@InProceedings{lee:emnlp16,
  author    = {Lee, Kenton  and  Lewis, Mike  and  Zettlemoyer, Luke},
  title     = {Global Neural CCG Parsing with Optimality Guarantees},
  booktitle = {Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  month     = {November},
  year      = {2016},
  address   = {Austin, Texas},
  publisher = {Association for Computational Linguistics},
  pages     = {2366--2376},
}

Encoder/decoder that can augment supervised X, Y pairs with additional latent x's given unpaired y's, e.g. given y produce x*, y for x* an inferred input. Allows semi-supervised training by adding additional data from unpaired y's to training set. Makes same semantics-token lexical assumption as Lapata's Seq2Tree (e.g. 'new york' token means 'new york' in ontology).
@InProceedings{kovcisky:emnlp16,
  title={Semantic parsing with semi-supervised sequential autoencoders},
  author={Ko{\v{c}}isk{\`y}, Tom{\'a}{\v{s}} and Melis, G{\'a}bor and Grefenstette, Edward and Dyer, Chris and Ling, Wang and Blunsom, Phil and Hermann, Karl Moritz},
  booktitle = {Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  month     = {November},
  year      = {2016},
  address   = {Austin, Texas},
  publisher = {Association for Computational Linguistics},
}

Develops a neural shift-reduce parser for linear time parsing using a lexicon and latent trees ported from a CKY CCG parser operating over the same training data. Can then run in linear time at test time, achieving similar performance to the polynomial time CKY parser. Introduces a strategy to learn from partial parses when CKY fails (which is often) by splitting tokens into smaller ``sentences'' based on spans that had reasonable parse sub-trees.
@InProceedings{misra:emnlp16,
  author =  "Misra, Dipendra and Artzi, Yoav",
  title =   "Neural Shift-Reduce CCG Semantic Parsing",
  booktitle =   "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
  year =  "2016",
  publisher =   "Association for Computational Linguistics",
  pages =   "1775--1786",
  location =  "Austin, Texas",
}

Uses semantic parsing plus execution model to do VQA with food web diagrams and world knowledge from LSTM encodings. Applied to the Jointly Learning to Parse and Perceive data for a marginal improvement as well.
@inproceedings{krishnamurthy:emnlp16,
  title={Semantic Parsing to Probabilistic Programs for Situated Question Answering.},
  author={Jayant Krishnamurthy and Oyvind Tafjord and Aniruddha Kembhavi},
  booktitle={Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  publisher={Association for Computational Linguistics},
  location={Austin, Texas},
  year={2016}
}

Dataset similar to VQA but focused on composition language requiring set-theoretic reasoning. Concocted scenes and task make the sentences complex, but not clearly translatable to an interesting or applicable task.
@inproceedings{suhr:acl17,
  title={A Corpus of Natural Language for Visual Reasoning.},
  author={Alane Suhr and Mike Lewis and James Yeh and Yoav Artzi},
  booktitle={Proceedings of the 2017 Conference of the Association for Computational Linguistics (ACL)},
  year={2017}
}

Grounded semantic parser learning in a blocks world. Given an utterance, candidate semantic parses are used to create world states resulting from executing those parses. The user selects the world state corresponding to the action they meant to convey, providing training data for the semantic parser between the utterance and semantic parse. Parser starts with no lexicon, but knows ontological actions, block positions, left/right, and colors. Parsing is done by a log-linear learner in an exponentially-sized feature space fo co-occurence counts for n-grams and semantic n-trees. Experiments are all single-user, not across multiple speakers. Requiring users to select the result world state makes this impractical in any embodied setting, since the agent there can only afford to perform a single action, not reliable communicate many hypothetical ones.
@inproceedings{wang:acl17,
  title={Learning language games through interaction},
  author={Wang, Sida I and Liang, Percy and Manning, Christopher D},
  booktitle={Proceedings of the 2017 Conference of the Association for Computational Linguistics (ACL)},
  year={2017}
}

The authors gather crowdsourced causality information for action verbs (e.g. 'chop' results in an object becoming multiple objects, 'heat' causes the temperature attribute to increase) and show that co-occurrence information between causality and language can help with grounding patient roles in the cooking domain (finding the 'patient' track in an associated video given a verbal description). Briefly also examine leave-one-action-out, using distributional semantics (ambiguously trained; maybe on just training sentences?) to represent observed actions, then using the annotations of the nearest neighbor action to the left-out action as surrogates, similar to our AAAI 2018 submission on object exploration, but less well-investigated.
@inproceedings{gao:acl16,
  title={Physical Causality of Action Verbs in Grounded Language Understanding},
  author={Q. Gao and M. Doering and S. Yang and J. Y. Chai},
  booktitle={Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)},
  location={Berlin, Germany},
  month={August},
  year={2016},
}

The authors present a pipeline for spoken language understanding that augments an ASR transcription with perceptual information to disambiguate referring expressions and actions and recover from transcription errors. For example, ``take the mobile into the bedroom'' initially misunderstood for a taking action (take FROM) is corrected to a bringing action (bring TO) when the distance between the mobile and the bedroom in a physical environment are considered. Memorizes lexical referring expressions for objects/places in the environment, rather than using attribute-based perception. Explores using distributional semantics to bridge the gap between unseen action/referring expression words and known ones, similar to our CoRL 2017 submission on object exploration, but less well-investigated.
@inproceedings{bastianelli:ijcai16,
  title={A Discriminative Approach to Grounded Spoken Language Understanding in Interactive Robotics.},
  author={Bastianelli, Emanuele and Croce, Danilo and Vanzo, Andrea and Basili, Roberto and Nardi, Daniele},
  booktitle = {Proceedings of the 25th International Joint Conference on Artificial Intelligence (IJCAI)},
  pages = {2747-2753},
  location = {New York City, New York},
  month = {July},
  year = {2016}
}

The authors present a deep learning framework for object category recognition that bootstraps from a small set of labeled examples to learn to correctly classify all objects (including majority unlabeled examples) with nearly state-of-the-art performance, losing only a few points from the same architecture used in a fully supervised setting. The algorithm uses co-training between the two modalities (RGB and D) to train separate networks and highlight examples in the unlabeled set that closely match a category, adding it as gold to the training set to bootstrap. When choosing objects to add as new "labeled" examples, latent attributes are first induced over all unlabeled examples using convex clustering, and attribute diversity within the predicted labels is encouraged to prevent overfitting to particular iconographic representations of a category. Additionally, the authors pre-train their recognition networks using an encoder/decoder framework, chopping off the decoder to allow the encoder to begin the recognition pipeline. Several cool ideas for moving forward with deep learning (e.g. for music or attribute prediction in multi-modal objects dataset).
@inproceedings{cheng:ijcai16,
  title={Semi-Supervised Multimodal Deep Learning for RGB-D Object Recognition.},
  author={Yanhua Cheng and Xin Zhao and Rui Cai and Zhiwei Li and Kaiqi Huang and Yong Rui},
  booktitle = {Proceedings of the 25th International Joint Conference on Artificial Intelligence (IJCAI)},
  pages = {3345-3351},
  location = {New York City, New York},
  month = {July},
  year = {2016}
}

The authors present a new dataset and task for labeling physical attributes between objects based on their verbal relationships given in raw text. For example ``person entering house'' suggests the person is physically smaller than the house. They introduce a factor graph model to jointly infer the relationships between pairs of objects given the verbs they particpate in together and considering the possible frames of those verbs during inference. Verb frames are labeled with task-specific attributes (size, weight, speed, etc.) by a Mechanical Turk task. The factor graph inference improves over simply using a MaxEnt classifier between objects given some seed set of object pairs labeled with attribute relations, with information shared between objects implicitly by representing them as thier GloVE embeddings.
@inproceedings{forbes:acl17,
  title={Verb Physics: Relative Physical Knowledge of Actions and Objects.},
  author={Maxwell Forbes and Yejin Choi},
  booktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL)},
  location = {Vancouver, Canada},
  month = {August},
  year = {2017}
}

The authors present a distributional semantics model in which words are represented as k-component gaussian mixture models, providing a mean vector for each word sense (component), and enabling appication in entailment detection using the covariance matrix around senses to search for overlaps. Limited by not selecting k dynamically, but instead fixing k=2 and k=3 in experiments. Shows improvements over single-sense ("point-based") distributional models like word2vec on several tasks.
@inproceedings{athiwaratkun:acl17,
  title={Multimodal Word Distributions.},
  author={Ben Athiwaratkun and Andrew Gordon Wilson},
  booktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL)},
  location = {Vancouver, Canada},
  month = {August},
  year = {2017}
}

The authors present an integrated robotic system for extracting faces, colors, objects, and activities in an unsupervised fashion from various sensors and processors that provide relevant feature modalities for each. Unsupervised clustering is used to form 'concepts' which can then be grounded to natural language in a soft-aligned supervised way using natural language descriptions of videos. Simple count statistics are used and an ILP is solved to join language unigrams to concepts present in the videos as discovered through unsupervised clustering. Close in spirit to a lot of BWI work we have done on grounding. Lacks robust language understanding and human-robot interaction components we aim to focus on.
@inproceedings{alomari:ijcai17,
  title={Grounding of Human Environments and Activities for Autonomous Robots.},
  author={Muhannad Alomari and Paul Duckworth and Nils Bore and Majd Hawasly and David C. Hogg and Anthony G. Cohn},
  booktitle = {Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI)},
  location = {Melbourne, Australia},
  month = {August},
  year = {2017}
}

The authors present an integration of open vocabulary semantic parsing (from unstructured text) and knowledge base-centric semantic parsing. They integrate KB knowledge by grounding possible semantic forms of against that KB and considering its responses as additional information to couple with the unstructured text parsing. The paper seems to lean heavily on Jayant's past work on open-vocabulary semantic parsing. The novel contribution, aside from integration, is encoding the KB information efficiently using a graph-to-feature isomorphism from Gardner. Overall probably not relevant to thesis work, but notable for scope and scale of learning from both unstructured and structured knowledge.
@inproceedings{gardner:aaai17,
  title={Open-Vocabulary Semantic Parsing with both Distributional Statistics and Formal Knowledge},
  author={Matt Gardner and Jayant Krishnamurthy},
  booktitle = {Proceedings of the 31st AAAI Conference on Artificial Intelligence},
  pages = {3195-3201},
  location = {San Francisco, California},
  month = {February},
  year = {2017}
}

@inproceedings{fulda:ijcai17,
  title={What Can You Do with a Rock? Affordance Extraction via Word Embeddings},
  author={Nancy Fulda and Daniel Ricks and Ben Murdoch and David Wingate},
  booktitle = {Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI)},
  pages = {1039-1045},
  location = {Melbourne, Australia},
  month = {August},
  year = {2017}
}

@inproceedings{gao:icra16,
  title={Deep learning for tactile understanding from visual and haptic data},
  author={Gao, Yang and Hendricks, Lisa Anne and Kuchenbecker, Katherine J and Darrell, Trevor},
  booktitle={International Conference on Robotics and Automation (ICRA)},
  pages={536--543},
  year={2016},
  organization={IEEE}
}

@inproceedings{alomari:aaai17,
  month = {February},
  author = {Muhannad Alomari and Paul Duckworth and David C. Hogg and Anthony G. Cohn},
  title = {Natural Language Acquisition and Grounding for Embodied Robotic Systems},
  booktitle = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence},
  pages = {4349--4356},
  year = {2017},
}

Mostly interested in the way the authors use variational auto-encoders to perturb sentence inputs to a model to create locally "semantically similar" sentences. Details in Section 4.1. Seems like something that could be relevant for generating additional training data in objects dataset someday (like vision-style pertubation of images), or bootstrapping from low-input data like the robot dataset when a general unsupervised corpus is available.
@inproceedings{alvarez-melis:emnlp17,
  month = {September},
  author = {David Alvarez-Melis and Tommi S. Jaakkola},
  title = {A causal framework for explaining the predictions of black-box sequence-to-sequence models},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  year = {2017},
}

The authors present a method for combining adjective/noun classifiers using a deep network to interpolate the linear SVM hyperplanes of those classifiers to form a new SVM hyperplane. The results aren't overwhelming, but the method is definitely worth citing for its ability to sort of handle polysemy in dealing with combinations of words that behave differently for different classes, eg. "red tomato" versus "red wine".
@inproceedings{misra:cvpr17,
  title={{From Red Wine to Red Tomato: Composition with Context}},
  author={Misra, Ishan and Gupta, Abhinav and Hebert, Martial},
  booktitle={CVPR},
  year={2017}
}

The authors present a state-of-the-art parsing model that uses a bidirectional LSTM to assign distributions over CCG supertags to input sentence tokens, followed by an A* search to select the correct parse. The model demonstrably performs better when given more data (for example, through semi-supervised tri-training), making it unsuitable for use in our low-resource tasks. Contains good references for CCG and for chart-parsing work within CCG. Explores augmenting parsing decisions with dependency parsing outputs with mixed results; take-away seemed to be that, given enough data, the LSTM-based model alone is sufficient to outperform a less-trained version with dependency information added.
@inproceedings{lewis:naacl16,
  title={LSTM CCG Parsing},
  author={Lewis, Mike and Lee, Kenton and Zettlemoyer, Luke},
  booktitle={Proceedings of the 15th Annual Conference of the North American Chapter of the Association for Computational Linguistics},
  year={2016}
}

Generate questions for annotation based on beam of possible parse trees in ambiguious sentences, providing the n options to resolve verb obj/subj ambiguities. Gets a modest boost over state-of-the-art, but overall the approach seems like it would help more when boostrapping a low-resource parser, or if PP attachment had been annotated through a similar quesion generation strategy.
@inproceedings{he:emnlp16,
  title={Human-in-the-Loop Parsing},
  author={He, Luheng and Michael, Julian and Lewis, Mike and Zettlemoyer, Luke},
  booktitle={Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  pages={2337--2342},
  publisher={Association for Computational Linguistics},
  location={Austin, Texas},
  year={2016}
}

The authors present a state-of-the-art system for both parsing sentences to AMR and parsing AMR to sentences. The novel contributions are a linearzation method for AMR (and analysis of the arbitrary nature of argument ordering), anonymization techniques for sentences into AMR graphs and vice versa, and a bootstrapping pre-training phase where unstructured text is used to close gaps in the wide, sparse vocabulary of the labeled AMR data. By iteratively parsing larger and larger samples of unstructured text and using these additional sentences for both parsing and generaion, vocabulary sparsity issues can be partially resolved and labeled training data better leveraged for final performance.
@inproceedings{konstas:acl17,
  title={Neural AMR: Sequence-to-Sequence Models for Parsing and Generation},
  author={Ioannis Konstas and Srinivasan Iyer and Mark Yatskar and Yejin Choi and Luke Zettlemoyer},
  booktitle={Proceedings of the 2017 Conference of the Association for Computational Linguistics (ACL)},
  year={2017}
}

The authors present an incremental parser learning algorithm for translating natural language queries directly into SQL queries. Translated queries are executed against a database, and unskilled users are shown those results (possibly augmented with type information and a paraphrase from training data, if available), and asked to mark correctness. Correcty labeled utterances and SQL can join the training data, while incorrect pairs are held for later annotation by experts. A natural direction for future work might be to generate these paraphrases automatically by jointly training an utterance -> SQL encoder/decoder plus an SQL -> utterance one, allowing arbitrary SQL to have paraphrase to ensure the human thinks the system has correctly understood them. Odd that they don't cite our incremental parser building from user feedback; maybe unaware of it? Jayant probably should know.
@inproceedings{iyer:acl17,
  title={Learning a Neural Semantic Parser from User Feedback},
  author={Srinivasan Iyer and Ioannis Konstas and Alvin Cheung and Jayant Krishnamurthy and Luke Zettlemoyer},
  booktitle={Proceedings of the 2017 Conference of the Association for Computational Linguistics (ACL)},
  year={2017}
}

@inproceedings{thomason:corl17,
  title = {Opportunistic Active Learning for Grounding Natural Language Descriptions},
  author = {Jesse Thomason and Aishwarya Padmakumar and Jivko Sinapov and Justin Hart and Peter Stone and Raymond J. Mooney},
  booktitle = {Proceedings of the 1st Annual Conference on Robot Learning (CoRL-17)},
  publisher = {Proceedings of Machine Learning Research},
  pages = {67-76},
  volume = {78},
  location = {Mountain View, California},
  month = {November},
  year = {2017}
}

@inproceedings{thomason:aaai18,
  title = {Guiding Exploratory Behaviors for Multi-Modal Grounding of Linguistic Descriptions},
  author = {Jesse Thomason and Jivko Sinapov and Raymond Mooney and Peter Stone},
  booktitle = {Proceedings of the 32nd Conference on Artificial Intelligence (AAAI-18)},
  location = {New Orleans, Louisiana},
  month = {February},
  year = {2018}
}

@inproceedings{tansey:aaai18,
  title = {Maximum-Variance Total Variation Denoising for Interpretable Spatial Smoothing},
  author = {Wesley Tansey and Jesse Thomason and James G Scott},
  booktitle = {Proceedings of the 32nd Conference on Artificial Intelligence (AAAI-18)},
  location = {New Orleans, Louisiana},
  month = {February},
  year = {2018}
}

@inproceedings{corona:ijcnlp17,
  title = {Improving Black-box Speech Recognition using Semantic Parsing},
  author = {Rodolfo Corona and Jesse Thomason and Raymond J. Mooney},
  booktitle = {Proceedings of the 8th International Joint Conference on Natural Language Processing (IJCNLP-17)},
  location = {Taipei, Taiwan},
  month = {November},
  year = {2017}
}

@inproceedings{padmakumar:eacl17,
  title = {Integrated Learning of Dialog Strategies and Semantic Parsing},
  author = {Aishwarya Padmakumar and Jesse Thomason and Raymond J. Mooney},
  booktitle = {Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics (EACL)},
  pages = {547-557},
  location = {Valencia, Spain},
  month = {April},
  year = {2017}
}

The authors extend the generalized grounding graph distributed correspondance graph formalism to include abstract concept collections like "row", "column" regions, cardinalities, and ordianlities, allowing the system to ground compositional noun phrases lke "middle block in the row of five blocks". They describe the changes required to the inference procedure to handle these abstract collections and also detail an approximate inference algorithm for beam-limiting the exponential search space introduced by the abstract factors in the graph. They demonstrate accuracy nearly matching a distributed correspondance graph with these abstract factors added when performing approximate inference with significant gains in runtime.
The core problem of grounding actions in the real world is related to my thesis work, and their approach to handle compositional language is orthogonal to using fully-fledged semantic parsing to understand nested statements like the example above, which could be handled in the lambda calculus formalism.
@INPROCEEDINGS{paul:rss16, 
  AUTHOR    = {Rohan Paul AND Jacob Arkin AND Nicholas Roy AND Thomas M. Howard}, 
  TITLE     = {Efficient Grounding of Abstract Spatial Concepts for Natural Language Interaction with Robot Manipulators}, 
  BOOKTITLE = {Proceedings of Robotics: Science and Systems}, 
  YEAR      = {2016}, 
  ADDRESS   = {Ann Arbor, Michigan}, 
  MONTH     = {June}
}
@article{paul:ijrr18,
  title={Efficient grounding of abstract spatial concepts for natural language interaction with robot platforms},
  author={Paul, Rohan and Arkin, Jacob and Aksaray, Derya and Roy, Nicholas and Howard, Thomas M},
  journal={The International Journal of Robotics Research},
  volume={37},
  number={10},
  pages={1269--1299},
  year={2018}
}

The authors present a system for executing user commands in context, remembering facts about the environment that may have been communicated in previous utterances. For example, if a person puts down a box and announces 'this is my snack', the system memorizes the fact that the box belongs to the person under the label 'snack' so that it can perform subsequent commands like 'point to my snack.' Uses temporal grounding graphs, building on ideas Stefanie laid out for referential grounding in the same lab in the past. Language understanding is done by a constituency parser and what seems like just counting alignment between the presence of words in certain phrases and real world referents. Perceptual categories are pre-defined, not learned, and can be matched to linguistic features. Less clunky than systems with lots of distinct components, since inference is contained in a single temporal graph and facts are encoded within that framework. More elegant than other lifelong learning systems. Facts probably don't translate well between users since words like 'my' should change between them. Robot isn't mobile, so just memorizing information about a tabletop environment. Perceptual classifiers pre-trained and fixed for things like object recognition. Looked like properties ('red', 'big') might be trained from actual data, but might also be pre-trained (skimmed finer details).
@inproceedings{paul:ijcai17,
  author    = {Rohan Paul and Andrei Barbu and Sue Felshin and Boris Katz and Nicholas Roy},
  title     = {Temporal Grounding Graphs for Language Understanding with Accrued Visual-Linguistic Context},
  booktitle = {Proceedings of the Twenty-Sixth International Joint Conference on
               Artificial Intelligence, {IJCAI-17}},
  pages     = {4506--4514},
  year      = {2017},
  doi       = {10.24963/ijcai.2017/629},
  url       = {https://doi.org/10.24963/ijcai.2017/629},
}

The authors present a system for memorizing unknown groundings and exploring objects to accrue observatons until the referenced object is discovered, allowing retroactive learning of previously unknown concepts. Unknown groundings can take the form of just unknown concept words or unknown object referents that may be located in a different part of the physical environment and must be sought out. For learning new concepts, this is closely related to our work on opportunistic active learning, especially as it is applied in PHM. In this work, each visual 'concept' that is learnable identifies a unique object, but the principles don't seem restricted to this case. Adjectives and descriptors are still used to help identify unknown objects, but these concepts were pre-trained (e.g. ``red'') and closed-category. Looks like an unknown concept noun (e.g. ``cone'') is assumed to apply to the first object with unknown category found when exploring the space! Mistaken associations must be washed out by future interactions. Overall an interesting paper and opens questions about whether multi-modal exploration / guiding exploratory behaviors could be added to a similar system to evaluate whether words applied to novel objects in an online fashion while also building feature representations of those objects (a direction of future work for PHM).
@inproceedings{tucker:isrr17,
  author    = {Mycal Tucker and Derya Aksaray and Rohan Paul and Gregory J. Stein and Nicholas Roy},
  title     = {Learning Unknown Groundings for Natural Language Interaction with Mobile Robots},
  booktitle = {International Symposium of Robotics Research, {ISRR-17}},
  year      = {2017},
}

@incollection{matuszek:er13,
  title={Learning to parse natural language commands to a robot control system},
  author={Matuszek, Cynthia and Herbst, Evan and Zettlemoyer, Luke and Fox, Dieter},
  booktitle={Experimental Robotics},
  pages={403--415},
  year={2013},
  publisher={Springer International Publishing}
}

@INPROCEEDINGS{eberhard:lrec10,
  author = {Eberhard, Kathleen and Nicholson, Hannele and K{\"{u}}bler, Sandra and Gunderson, Susan and Scheutz, Matthias},
  title = {{The Indiana ``Cooperative Remote Search Task'' (CReST) Corpus}},
  booktitle = {LREC},
   year = {2010}
}

@inproceedings{cantrell:hri12,
   author = {Cantrell, Rehj and Talamadupula, Kartik and Schermerhorn, Paul and Benton, J. and Kambhampati, Subbarao and Scheutz, Matthias},
   title = {Tell Me when and Why to Do It!: Run-time Planner Model Updates via Natural Language Instruction},
   booktitle = {Proceedings of the Seventh Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
   year = {2012},
   isbn = {978-1-4503-1063-5},
   location = {Boston, Massachusetts, USA},
   pages = {471--478},
   numpages = {8},
   url = {http://doi.acm.org/10.1145/2157689.2157840},
   doi = {10.1145/2157689.2157840},
   acmid = {2157840},
   publisher = {ACM},
   address = {New York, NY, USA},
} 

@INPROCEEDINGS{tellex:aaai11,
  author = {Stefanie Tellex and Thomas Kollar and Steven Dickerson and Matthew R. Walter and Ashis Gopal Banerjee and Seth Teller and Nicholas Roy},
  title = {Understanding Natural Language Commands for Robotic Navigation and Mobile Manipulation},
  booktitle = {Proceedings of the National Conference on Artificial Intelligence (AAAI)},
  year = {2011}
}

@inproceedings{klein:acl03,
  author = {Klein, Dan and Manning, Christopher D.},
  title = {Accurate Unlexicalized Parsing},
  booktitle = {Proceedings of the 41st Annual Meeting on Association for Computational Linguistics (ACL) - Volume 1},
  year = {2003},
  location = {Sapporo, Japan},
  pages = {423--430},
  numpages = {8},
  url = {http://dx.doi.org/10.3115/1075096.1075150},
  doi = {10.3115/1075096.1075150},
  acmid = {1075150},
  publisher = {Association for Computational Linguistics},
  address = {Stroudsburg, PA, USA},
} 

@article{khandelwal:ijrr17,
  title = {BWIBots: A platform for bridging the gap between AI and human--robot interaction research},
  author = {Piyush Khandelwal and Shiqi Zhang and Jivko Sinapov and Matteo Leonetti and Jesse Thomason and Fangkai Yang and Ilaria Gori and Maxwell Svetlik and Priyanka Khante and Vladimir Lifschitz and J. K. Aggarwal and Raymond Mooney and Peter Stone},
  journal = {The International Journal of Robotics Research (IJRR)},
  volume = {36},
  month = {February},
  year = {2017}
}

@article{roy:evocomm01,
  Author =  "Deb Roy",
  title = "Learning Visually Grounded Words and Syntax of Natural
     Spoken Language",
  journal = "Evolution of Communication",
  volume = "4",
  number = "1",
  year = "2001"
}

@article{settles:um10,
  title={Active learning literature survey},
  author={Settles, Burr},
  journal={University of Wisconsin, Madison},
  volume={52},
  number={55-66},
  pages={11},
  year={2010}
}

@inproceedings{lewis:sigir94,
  title={A sequential algorithm for training text classifiers},
  author={Lewis, David D and Gale, William A},
  booktitle={Proceedings of the 17th annual international ACM SIGIR conference on Research and development in information retrieval},
  pages={3--12},
  year={1994},
  organization={Springer-Verlag New York, Inc.}
}

@inproceedings{settles:emnlp08,
  title={An analysis of active learning strategies for sequence labeling tasks},
  author={Settles, Burr and Craven, Mark},
  booktitle={Proceedings of the conference on empirical methods in natural language processing},
  pages={1070--1079},
  year={2008},
  organization={Association for Computational Linguistics}
}

@inproceedings{cakmak:hri12, 
  author={M. Cakmak and A. L. Thomaz}, 
  booktitle={Human-Robot Interaction (HRI), 2012 7th ACM/IEEE International Conference on}, 
  title={Designing robot learners that ask good questions}, 
  year={2012}, 
  pages={17-24}, 
  ISSN={2167-2121}, 
  month={March}
}

@inproceedings{lutkebohle:icra09,
  title={The curious robot-structuring interactive robot learning},
  author={Lutkebohle, Ingo and Peltason, Julia and Schillingmann, Lars and Wrede, Britta and Wachsmuth, Sven and Elbrechter, Christof and Haschke, Robert},
  booktitle={Robotics and Automation, 2009. ICRA'09. IEEE International Conference on},
  pages={4156--4162},
  year={2009},
  organization={IEEE}
}

@article{skovcaj:jetai16,
  title={An integrated system for interactive continuous learning of categorical knowledge},
  author={Sko{\v{c}}aj, Danijel and Vre{\v{c}}ko, Alen and Mahni{\v{c}}, Marko and Jan{\'\i}{\v{c}}ek, Miroslav and Kruijff, Geert-Jan M and Hanheide, Marc and Hawes, Nick and Wyatt, Jeremy L and Keller, Thomas and Zhou, Kai and others},
  journal={Journal of Experimental \& Theoretical Artificial Intelligence},
  volume={28},
  number={5},
  pages={823--848},
  year={2016},
  publisher={Taylor \& Francis}
}

@article{cakmak:tamd10, 
  author={M. Cakmak and C. Chao and A. L. Thomaz}, 
  journal={IEEE Transactions on Autonomous Mental Development}, 
  title={Designing Interactions for Robot Active Learners}, 
  year={2010}, 
  volume={2}, 
  number={2}, 
  pages={108-118}, 
  ISSN={1943-0604}, 
  month={June}
}

@inproceedings{kulick:ijcai13,
 author = {Kulick, Johannes and Toussaint, Marc and Lang, Tobias and Lopes, Manuel},
 title = {Active Learning for Teaching a Robot Grounded Relational Symbols},
 booktitle = {Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence},
 year = {2013},
 isbn = {978-1-57735-633-2},
 location = {Beijing, China},
 pages = {1451--1457},
 numpages = {7},
 acmid = {2540337},
 publisher = {AAAI Press},
}

@inproceedings{bisk:naacl16,
  author = {Bisk, Yonatan and Yuret, Deniz and Marcu, Daniel},
  title = {Natural Language Communication with Robots},
  booktitle = {Proceedings of the 15th Annual Conference of the North American Chapter of the Association for Computational Linguistics},
  month={June},
  pages= {751--761},
  address={San Diego, CA},
  year = {2016},
}

@inproceedings{kollar:icra13, 
  author={Thomas Kollar and Vittorio Perera and Daniele Nardi and Manuela Veloso}, 
  booktitle={Proceedings of the 2013 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={{Learning Environmental Knowledge from Task-Based Human-Robot Dialog}}, 
  year={2013}, 
  pages={4304-4309}, 
}

@inproceedings{taylor:esca98,
  author = {Paul Taylor and Alan W Black and Richard Caley},
  title = {The Architecture Of The Festival Speech Synthesis System},
  booktitle = {In the Third ESCA Workshop in Speech Synthesis},
  year = {1998},
  pages = {147--151},
  publisher = {}
}

@article{sharma:kdd17,
  title={Evidence-based uncertainty sampling for active learning},
  author={Sharma, Manali and Bilgic, Mustafa},
  journal={Data Mining and Knowledge Discovery},
  volume={31},
  number={1},
  pages={164--202},
  year={2017},
  publisher={Springer}
}

@inproceedings{mccarthy:semeval07,
  title={Semeval-2007 task 10: English lexical substitution task},
  author={McCarthy, Diana and Navigli, Roberto},
  booktitle={Proceedings of the 4th International Workshop on Semantic Evaluations},
  pages={48--53},
  year={2007},
  organization={Association for Computational Linguistics}
}

@Inbook{kanishcheva:iasais16,
  author="Kanishcheva, Olga and Angelova, Galia",
  editor="Margenov, Svetozar and Angelova, Galia and Agre, Gennady",
  title="About Sense Disambiguation of Image Tags in Large Annotated Image Collections",
  bookTitle="Innovative Approaches and Solutions in Advanced Intelligent Systems ",
  year="2016",
  publisher="Springer International Publishing",
  pages="133--149"
}

@inproceedings{deselears:cvpr11,
  author = {Thomas Deselaers and Vittorio Ferrari},
  title = {Visual and Semantic Similarity in ImageNet},
  booktitle = {Computer Vision and Pattern Recognition},
  pages = {1777-178},
  location = {Colorado Springs, Colorado},
  month = {June},
  year = {2011}
}

@InProceedings{kiela:acl15,
  author    = {Kiela, Douwe  and  Rimell, Laura  and  Vuli\'{c}, Ivan  and  Clark, Stephen},
  title     = {Exploiting Image Generality for Lexical Entailment Detection},
  booktitle = {Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)},
  month     = {July},
  year      = {2015},
  address   = {Beijing, China},
  pages     = {119--124}
}

@article{deerwester:asis90,
  author = {Scott Deerwester and Susan T. Dumais and George W. Furnas and Thomas K. Landauer and Richard Harshman},
  title = {Indexing by latent semantic analysis},
  journal = {Journal of the American Society for Information Science},
  year = {1990},
  volume = {41},
  number = {6},
  pages = {391--407}
}

@inproceedings{mikolov:nips13,
 author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
 title = {Distributed Representations of Words and Phrases and Their Compositionality},
 booktitle = {Proceedings of the 26th International Conference on Neural Information Processing Systems},
 year = {2013},
 address = {Lake Tahoe, Nevada},
 pages = {3111--3119}
}

@article{bruni:jair14,
  author = "Elia Bruni and Nam Khanh Tran and Marco Baroni",
  title = "Multimodal Distributional Semantics",
  journal = "Journal of Artificial Intelligence Research",
  volume = "49",
  pages = "1--47",
  year = "2014"
}

@inproceedings{navigli:sem13,
  title={Semeval-2013 task 11: Word sense induction and disambiguation within an end-user application},
  author={Navigli, Roberto and Vannella, Daniele},
  year={2013},
  booktitle = {In Second Joint Conference on Lexical and Computational Semantics},
}

@article{araki:ar12,
  title={Online object categorization using multimodal information autonomously acquired by a mobile robot},
  author={Araki, Takaya and Nakamura, Tomoaki and Nagai, Takayuki and Funakoshi, Kotaro and Nakano, Mikio and Iwahashi, Naoto},
  journal={Advanced Robotics},
  volume={26},
  number={17},
  pages={1995--2020},
  year={2012},
  publisher={Taylor \& Francis}
}

@inproceedings{chu:icra13,
  title={Using robotic exploratory procedures to learn the meaning of haptic adjectives},
  author={Chu, Vivian and McMahon, Ian and Riano, Lorenzo and McDonald, Craig G and He, Qin and Perez-Tejada, Jorge Martinez and Arrigo, Michael and Fitter, Naomi and Nappo, John C and Darrell, Trevor and others},
  booktitle={Robotics and Automation (ICRA), 2013 IEEE International Conference on},
  pages={3048--3055},
  year={2013},
  organization={IEEE}
}

@inproceedings{silberer:acl14,
  title={Grounded Meaning Representations with Autoencoders},
  author={Carina Silberer and Mirella Lapata},
  booktitle={In Proceedings of the Association for Computational Linguistics (ACL)},
  location={Baltimore, Maryland},
  year={2014},
}

@inproceedings{zhang:aaaiss17,
  title={Robot Behavioral Exploration and Multimodal Perception using POMDPs},
  author={Zhang, Shiqi and Sinapov, Jivko and Wei, Suhua and Stone, Peter},
  booktitle = {AAAI Spring Symposium on Interactive Multi-sensory Object Perception for Embodied Agents},
  location = {Stanford, CA},
  month = {March},
  year = {2017}
}

@article{lynott:brm09,
  title = "Modality exclusivity norms for 423 object properties",
  author = "Dermot Lynott and Louise Connell",
  year = "2009",
  volume = "41",
  pages = "558--564",
  journal = "Behavior Research Methods",
  issn = "1554-351X",
  publisher = "Springer New York",
  number = "2"
}

@inproceedings{melamud:acl15,
  title = {A simple word embedding model for lexical substitution},
  author = {Oren Melamud and Omer Levy and Ido Dagan},
  booktitle = {Proceedings of the 1st Workshop on Vector Space Modeling for Natural Language Processing},
  publisher = {Association for Computational Linguistics},
  month = {June},
  address = {Denver, Colorado},
  pages = {1--7},
  year = {2015},
}

@inproceedings{lazaridou:naacl15,
  title={Combining Language and Vision with a Multimodal Skipgram Model},
  author={Angeliki Lazaridou and Nghia The Pham and Marco Baroni},
  booktitle={The Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)},
  year={2015}
}

@inproceedings{kottur:cvpr16,
  title={Visual Word2vec (vis-w2v): Learning Visually grounded Word Embeddings Using Abstract Scenes},
  author={Satwik Kottur and Ramakrishna Vedantam and Jos\'{e} M. F. Moura and Devi Parikh},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  organization={IEEE}
}

@inproceedings{vijayakumar:emnlp17,
  title={Sound-word2vec: Learning word representations grounded in sounds},
  author={Vijayakumar, Ashwin K and Vedantam, Ramakrishna and Parikh, Devi},
  booktitle={Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  publisher = {Association for Computational Linguistics},
  address = {Copenhagen, Denmark},
  month = {September},
  pages = {920--925},
  year={2017}
}

@inproceedings{xian:cvpr2017,
  title = {Zero-Shot Learning - the Good, the Bad and the Ugly},
  author = {Yongqin Xian and Bernt Schiele and Zeynep Akata},
  booktitle = {Proceedings of the 30th IEEE Conference on Computer Vision and Pattern Recognition (CVPR-17)},
  location = {Honolulu, Hawaii},
  month = {July},
  year = {2017}
}

@inproceedings{fu:cvpr15,
  title={Zero-shot object recognition by semantic manifold distance},
  author={Fu, Zhenyong and Xiang, Tao and Kodirov, Elyor and Gong, Shaogang},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2635--2644},
  year={2015}
}

@inproceedings{kodirov:iccv15,
author = {Kodirov, Elyor and Xiang, Tao and Fu, Zhenyong and Gong, Shaogang},
title = {Unsupervised Domain Adaptation for Zero-Shot Learning},
booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
month = {December},
year = {2015}
} 

@book{kruskal:sage78,
  title={Multidimensional scaling},
  author={Kruskal, Joseph B and Wish, Myron},
  volume={11},
  year={1978},
  publisher={Sage}
}

@article{younger:ic67,
  author = "Daniel Younger",
  title = "Recognition and parsing of context-free languages in time $n^3$",
  journal = "Information and Control",
  volume = "10",
  issue = "2",
  pages = "189--208",
  year = "1967"
}

@book{sipser:mit97,
  title={Introduction to the Theory of Computation},
  author={Michael Sipser},
  year={1978},
  publisher={MIT Press}
}

@inproceedings{kwiatkowski:emnlp10,
  title={Inducing Probabilistic CCG Grammars from Logical Form with Higher-Order Unification},
  author={Kwiatkowski, Tom and Zettlemoyer, Luke and Goldwater, Sharon and Steedman, Mark},
  booktitle={Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year=2010,
  pages={1223--1233}
}

@inproceedings{christie:emnlp16,
  title = {Resolving Language and Vision Ambiguities Together: Joint Segmentation \& Prepositional Attachment Resolution in Captioned Scenes},
  author = {Gordon Christie and Ankit Laddha and Aishwarya Agrawal and Stanislaw Antol and Yash Goyal and Kevin Kochersberger and Dhruv Batra.},
  year = {2016},
  booktitle = {Conference on Empirical Methods in Natural Language Processing (EMNLP)}
}

@inproceedings{thomason:naacl13,
  title = {Differences in User Responses to a Wizard-of-Oz versus Automated System},
  author = {Jesse Thomason and Diane Litman},
  booktitle = {Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)},
  pages = {796-801},
  location = {Atlanta, GA},
  month = {June},
  year = {2013}
}

@inproceedings{krizhevsky:nips12,
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  title = {ImageNet Classification with Deep Convolutional Neural Networks},
  booktitle = {Proceedings of the 25th International Conference on Neural Information Processing Systems (NIPS)},
  year = {2012},
  location = {Lake Tahoe, Nevada},
  pages = {1097--1105},
} 

@inproceedings{dong:acl16,
  author = {Li Dong and Mirella Lapata},
  title = {Language to Logical Form with Neural Attention},
  booktitle = {Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)},
  year = {2016},
  location = {Berlin, Germany},
  pages = {33--43},
} 

@inproceedings{jia:acl16,
  author = {Robin Jia and Percy Liang},
  title = {Data Recombination for Neural Semantic Parsing},
  booktitle = {Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)},
  year = {2016},
  location = {Berlin, Germany},
  pages = {12--22},
} 

@inproceedings{burchfiel:rss17,
  author = {Benjamin Burchfiel and George Konidaris},
  title = {Generalized 3D Object Representations using Bayesian Eigenobjects},
  booktitle = {Proceedings of Robotics: Science and Systems (RSS)},
  year = {2017},
  location = {Cambridge, Massachusetts},
} 

@inproceedings{henricks:eccv16,
  author = {Lisa Anne Hendricks and Zeynep Akata and Marcus Rohrbach and Jeff Donahue and Bernt Schiele and Trevor Darrell},
  title = {Generative Visual Explanations},
  booktitle = {Proceedings of the 14th European Conference on Computer Vision (ECCV)},
  year = {2016},
  location = {Amsterdam, The Netherlands},
} 

@article{barrett:corr15,
  author    = {Daniel Paul Barrett and Scott Alan Bronikowski and Haonan Yu and Jeffrey Mark Siskind},
  title     = {Robot Language Learning, Generation, and Comprehension},
  journal   = {CoRR},
  year      = {2015},
  volume={abs/1508.06161}
}

@inproceedings{mao:iccv15,
  author = {Mao, Junhua and Wei, Xu and Yang, Yi and Wang, Jiang and Huang, Zhiheng and Yuille, Alan L.},
  title = {Learning Like a Child: Fast Novel Visual Concept Learning From Sentence Descriptions of Images},
  booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
  month = {December},
  year = {2015}
}

@article{yuruten:ab13,
  title={The learning of adjectives and nouns from affordance and appearance features},
  author={Y{\"u}r{\"u}ten, Onur and {\c{S}}ahin, Erol and Kalkan, Sinan},
  journal={Adaptive Behavior},
  volume={21},
  number={6},
  pages={437--451},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{zitnik:cvpr13,
  author = {Larry Zitnick and Devi Parikh},
  title = {Bringing Semantics Into Focus Using Visual Abstraction},
  booktitle = {Computer Vision and Pattern Recognition (CVPR)},
  month = {December},
  year = {2013}
}

@inproceedings{gemignani:aamas15,
  author = {Guglielmo Gemignani and Emanuele Bastianelli and Daniele Nardi},
  title = {Teaching Robots Parametrized Executable Plans Through Spoken Interaction},
  booktitle = {Proceedings of the 14th International Conference on Autonomous Agents and Multiagent Systems (AAMAS)},
  location = {Istanbul, Turkey},
  month = {May},
  year = {2015}
}

@inproceedings{whitney:icra17,
  author = {David Whitney and Eric Rosen and James MacGlashan and Lawson L. S. Wong and Stefanie Tellex},
  title = {Reducing errors in object-fetching interactions through social feedback},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  location = {Singapore},
  month = {June},
  year = {2017}
}

@inproceedings{das:iccv17,
  title={Learning Cooperative Visual Dialog Agents with Deep Reinforcement Learning},
  author={Abhishek Das and Satwik Kottur and Jos\'e M.F. Moura and
    Stefan Lee and Dhruv Batra},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  year={2017}
}

@article{silberer:pami17,
  title={Visually grounded meaning representations},
  author={Silberer, Carina and Ferrari, Vittorio and Lapata, Mirella},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={39},
  number={11},
  pages={2284--2297},
  year={2017},
  publisher={IEEE}
}

Discussion of the need for considering common ground when performing actions (including behaviors and speaking) as a robot, since humans make inferences about what is done and what is left out based on common ground. Provides a few case studies and a call to action for future work to consider common ground.
@inproceedings{knepper:hri17,
 author = {Knepper, Ross A. and Mavrogiannis, Christoforos I. and Proft, Julia and Liang, Claire},
 title = {Implicit Communication in a Joint Action},
 booktitle = {Proceedings of the 2017 ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
 year = {2017},
 location = {Vienna, Austria},
 pages = {283--292},
} 

@article{baltruvsaitis:mm17,
  title={Multimodal Machine Learning: A Survey and Taxonomy},
  author={Baltru{\v{s}}aitis, Tadas and Ahuja, Chaitanya and Morency, Louis-Philippe},
  journal={arXiv preprint arXiv:1705.09406},
  year={2017},
  volume={1705}
}

@article{brodeur:home17,
  title={HoME: A household multimodal environment},
  author={Brodeur, Simon and Perez, Ethan and Anand, Ankesh and Golemo, Florian and Celotti, Luca and Strub, Florian and Rouat, Jean and Larochelle, Hugo and Courville, Aaron},
  journal={arXiv preprint arXiv:1711.11017},
  year={2017},
  volume={1711}
}

Presents and justifies the use of embedding space for gestures to recognize novel gestures in a zero-shot way, understanding them based on their location in the embedding space. Leverages commonalities between sub-gestures in semantically related ones (gesture morphemes, basically) and coincident gesture and language in a training corpus.
@inproceedings{thomason:iser16,
 author = {Wil Thomason and Ross A. Knepper},
 title = {Recognizing Unfamiliar Gestures for Human-Robot
Interaction through Zero-Shot Learning},
 booktitle = {International Symposium on Experimental Robotics (ISER)},
 year = {2016},
 location = {Tokyo, Japan},
} 

@article{tuia:plos16,
  author = "Devis Tuia and Gustau Camps-Valls",
  title = "Kernel Manifold Alignment for Domain Adaptation",
  journal = "PLoS ONE",
  volume = "11",
  issue = "2",
  year = "2016"
}

@inproceedings{ring:iciva16,
  author = "Lazlo Ring and Dina Utami and Stefan Olafsson and Timothy Bickmore",
  title = "Increasing Engagement with Virtual Agents Using Automatic Camera Motion",
  booktitle = "International Conference on Intelligent Virtual Agents",
  publisher = "Springer",
  year = "2016",
  pages = "29--39"
}

@article{su:csl18,
  author = "Pei-Hao Su and Milica Ga{\v{s}}i{\'c} and Steve Young",
  title = "Reward estimation for dialogue policy optimisation",
  journal = "Computer Speech and Language",
  year = "2018"
}

Presents a new type of deep contextualized word representations, ELMo (Embeddings from Language Models). The ELMo word representations are context-dependent, formed from a multi-layer biLSTM pre-trained on a large text corpus. By forming a word-level vector from the sentence context, word sense is handled in a continuous fashion. By allowing models using ELMo to attend over multiple layers of the biLSTM, complex characteristics of words (e.g. syntax versus semantics) can be attended to as necessary for a specific supervised task. The authors plug ELMo in as input to several supervised tasks' state-of-the-art models and demonstrate performance gains on each from these representations.
Comparisons are consistently made to CoVe (McCann et al., 2017). CoVe vectors are initialized from a seq-2-seq MT model, and so in expectation should have a better handle on polysemy. CoVe also improved over a suite of state of the art methods, but ELMo surpasses these as well, presumably because of being able to consider multiple biLSTM layers and being initialized on a larger unsupervised (rather than parallel) corpus.
The model also incorporates or perhaps operates at the character-level, using character convolutions to build up initial word representations, but this is detailed in other work on which their model architecture is based (Jozefowicz et al., 2016).
@inproceedings{peters:naacl18,
  author = {Matthew E. Peters and Mark Neumann and Mohit Iyyer and Matt Gardner and Christopher Clark and Kenton Lee and Luke Zettlemoyer},
  title = {Deep contextualized word representations},
  booktitle = {Proceedings of the 16th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)},
  year = {2018}
}

Presents a character-level CNN feeding into a large LSTM trained for on the One Billion Word Benchmark. Explores CNN-based softmax to reduce the number of parameters while maintaining relatively competitive perplexity. CNN-level inputs followed by LSTM with sampling-based softmax of words achieve SoTA perlexicty results on the dataset for a single model. 
@misc{jozefowicz:arxiv16,
title = {Exploring the limits of language modeling},
author  = {Rafal Jozefowicz and Oriol Vinyals and Mike Schuster and Noam Shazeer and Yonghui Wu},
year  = {2016},
URL = {https://arxiv.org/pdf/1602.02410.pdf}
}

Presents a model for multi-modal emoji prediction over 5, 10, or 20 emoji classes. Framed to take in Instragram photo, text, or both, and produce classification decision. Provides light qualitative analysis. Would be more interesting as a general language modeling problem (e.g. how can language models benefit from multi-modal input representations like a photograph; LM for captions may not necessarily describe contents but instead provide context or feeling related to image, especially on Instagram). Also might be interesting to run ELMo-style embedding models over tweets/instagram captions to find different context vectors for emoji as a basis for discovering their sense usage.
@inproceedings{barbieri:naacl18,
  author = {Francesco Barbieri and Miguel Ballesteros and Francesco Ronzano and Horacio Saggion},
  title = {Multimodal Emoji Prediction},
  booktitle = {Proceedings of the 16th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)},
  year = {2018}
}

[[note: update when actually published at EMNLP]]
Presents an extension to SQuAD data in which a questioner requests information from an unseen document in a dialog setting, enabling questions to refer to text in both previous questions and previous answers. An extended initial baseline is adapted from a SotA SQuAD system and shown to perform at 23.8 F1 below human performance, allowing for a wide possible improvement for future models. Answerer must provide spans of text or "no answer" option, enabling easier automated evaluation as a span identification problem. Answerers provide questioners with not just an answer but a next-dialog-act (whether the questioner should follow-up). Answers can be affirmations, which must be justified with a text span. Qualitatively, most questions coreference document entities, and a sizeable minority reference dialog history.
Q: Paper mentions (and samples show) many questions boil down to "is there something interesting in the article"; how can we really evaluate open-ended questiosn like this? If the task isn't restricted to ensure answer uniqueness, the evaluation needs to somehow account for the possible duplicity of answers in the way it allows for unanswerables. Table 3 summarizes these questions as an "Anything else" category. These don't explicitly fall out from the F1<.4 filter mentioned in 4.1.
A(ish): "we report the average of the maximum F1 computed from each n − 1 subset with respect to the heldout reference."
@inproceedings{choi:emnlp18,
  author = {Eunsol Choi and He He and Mohit Iyyer and Mark Yatskar and Scott Yih and Yejin Choi and Percy Liang and Luke Zettlemoyer},
  title = {{QuAC}: Question Answering in Context},
  booktitle = {EMNLP},
  year = {2018}
}


Presents INGRESS (INteractive visual Grounding of Referring ExpreSSions), a referring expression grounding and disambiguation system for embodied use that asks clarification questions about candidate objects with a combination of text and gesture. Approach is based on grounding by generation, a two-stage model that first generates candidate visual descriptions to compare against input language to identify candidates. The second examines pairwise object relations between candidates to select the most likely. These models can be used for referring expression generation to ask clarication questions, e.g., "do you mean this green tennis ball on the table?"
vid: https://www.youtube.com/watch?v=13KsDgmV0vE&feature=youtu.be
Strenghts:
  - networks are trained for generation + grounding, allowing for referring expression generation; seems related to other models where training can be augmented with generation, but wonder if training just for grounding task would have improved performance when RE is unambiguous.
  - use METEOR metric to calculate loss between two REs in addition to cross-entropy loss; wonder if better/interesting perf could come from average embedding vector of two REs?
  - generates REs uniquely (self-referring) or backs off to relational if self-referring METEOR is small.
  - users can provide 'yes'/'no'/correcting responses.
Limitations:
  - Visual binary relations between objects; what about superlatives, non-visual comparisons (e.g., "full" for the kitchen).
  - System is mostly out-of-the-box components stuffed together; very application-driven and maybe limited to this setting as a consequence.
  - System is unable to handle ordinal descriptions like "the second can from the right on the top row"; this is common and hard for LSTM-like models, but might come up frequently in real world domains like a kitchen-helper robot.
?s:
  - Figure 2, do pairs of image regions generate a single referring expression or one for each image in the pair?
  - Image feature vector (III.B) is gigantic surely it could have been shrunk to 128ish for this task (so large because using pre-trained network on a much more diverse set of images).
  - Does including the whole image as a special pairing "object" actually improve performance?
  - Could perspective correction have been skipped by simply training a model from each perspective and using the one with greater confidence at test time?
@INPROCEEDINGS{shrindhar:rss18, 
    AUTHOR    = {Mohit Shridhar AND David Hsu}, 
    TITLE     = {Interactive Visual Grounding of Referring Expressions for Human-Robot Interaction}, 
    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, 
    YEAR      = {2018}, 
    ADDRESS   = {Pittsburgh, Pennsylvania}, 
    MONTH     = {June}, 
    DOI       = {10.15607/RSS.2018.XIV.028} 
} 

@inproceedings{kasaei:aaai18,
  author = {S. Hamidreza Kasaei and Juil Sock and Lu\'is and Seabra Lopes and Ana Maria Tom\'e and Tae-Kyun Kim},
  title = {Perceiving, Learning, and Recognizing 3D Objects: An Approach to Cognitive Service Robots},
  booktitle = {Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence (AAAI)},
  year = {2018}
}

@inproceedings{chen:hri18,
  author = {Min Chen and Stefanos Nikolaidis and Harold Soh and David Hsu and Siddhartha Srinivasa},
  title = {Planning with Trust for Human-Robot Collaboration},
  booktitle = {Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
  year = {2018}
}

@inproceedings{kulick:ijcai13,
 author = {Kulick, Johannes and Toussaint, Marc and Lang, Tobias and Lopes, Manuel},
 title = {Active Learning for Teaching a Robot Grounded Relational Symbols},
 booktitle = {Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence (IJCAI)},
 year = {2013},
 location = {Beijing, China},
 pages = {1451--1457},
 numpages = {7},
 acmid = {2540337},
 publisher = {AAAI Press},
} 

Discussed during her SIGDIAL 2018 keynote.
@article{zukerman:csl15,
title = "Employing distance-based semantics to interpret spoken referring expressions",
author = "Ingrid Zukerman and Su Nam Kim and Thomas Kleinbauer and Masud Moshtaghi",
year = "2015",
volume = "34",
pages = "154--185",
journal = "Computer Speech and Language",
publisher = "Elsevier",
}

The authors present a new task paradigm and associated starting dataset for Embodied Question Answering. An agent is dropped at a random location within a simulated environment and given a question in natural language (e.g. ``What color is the car?''). It must then take navigation actions (turning and moving forward) until the question can be answered, using only an RGB camera signal as additional input. The agent is trained end-to-end using composed CNNs and LSTMs, with various pre-training techniques used to initialize module components. The authors use Adaptive Computation Time (ACT) RNNs to separate the planner and controller for navigation, meaning one module selects a direction and another selects how far forward to move based on the intent of that direction. One weakness of the model is that the set of possible answers is both finite and known in advance: the question-answering module creates a ranked list of possible answers as the softmax output layer. One possible direction for future work would be to generate answers from an LSTM model and compare them to the ground truth answers. The design of this particular dataset lends itself to a closed space of answers (questions are generated from functional programs run against the environment). As it relates to our work, this represents a nice step towards integrating navigation with command (here, question) execution, by treating language as an input signal to be reasoned with alongside environmental constraints.
@inproceedings{das:cvpr18,
  title = {Embodied Question Answering},
  author = {Abhishek Das and Samyak Datta and Georgia Gkioxari and Stefan Lee and Devi Parikh and Dhruv Batra},
  year = {2018},
  booktitle = {CVPR}
}

@article{fischler:acm81,
 author = {Fischler, Martin A. and Bolles, Robert C.},
 title = {Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography},
 journal = {Commun. ACM},
 issue_date = {June 1981},
 volume = {24},
 number = {6},
 month = jun,
 year = {1981},
 issn = {0001-0782},
 pages = {381--395},
 numpages = {15},
 url = {http://doi.acm.org/10.1145/358669.358692},
 doi = {10.1145/358669.358692},
 acmid = {358692},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {automated cartography, camera calibration, image matching, location determination, model fitting, scene analysis},
} 

@InProceedings{rusu:icra11,
  author    = {Radu Bogdan Rusu and Steve Cousins},
  title     = {{3D is here: Point Cloud Library (PCL)}},
  booktitle = {{IEEE International Conference on Robotics and Automation (ICRA)}},
  month     = {May 9-13},
  year      = {2011},
  address   = {Shanghai, China}
} 

The MatterPort R2R dataset and simulator.
@inproceedings{anderson:cvpr18,
  title={{Vision-and-Language Navigation}: Interpreting visually-grounded navigation instructions in real environments},
  author={Peter Anderson and Qi Wu and Damien Teney and Jake Bruce and Mark Johnson and Niko S{\"u}nderhauf and Ian Reid and Stephen Gould and Anton van den Hengel},
  booktitle={CVPR},
  year={2018}
}

@article{chang:3dv17,
  title={{Matterport3D}: Learning from {RGB-D} Data in Indoor Environments},
  author={Chang, Angel and Dai, Angela and Funkhouser, Thomas and Halber, Maciej and Niessner, Matthias and Savva, Manolis and Song, Shuran and Zeng, Andy and Zhang, Yinda},
  journal={3DV},
  year={2017}
}

Daniel Gordon's IQA paper and dataset.
@inproceedings{gordon2018iqa,
  title={{IQA}: Visual Question Answering in Interactive Environments},
  author={Gordon, Daniel and Kembhavi, Aniruddha and Rastegari, Mohammad and Redmon, Joseph and Fox, Dieter and Farhadi, Ali},
  booktitle={CVPR},
  year={2018},
}

@article{anderson:oneqa18,
  title={{Vision-and-Language Navigation}: Interpreting visually-grounded navigation instructions in real environments},
  author={Peter Anderson and Angel Chang and Devendra Singh Chaplot and Alexey Dosovitskiy and Saurabh Gupta and Vladlen Koltun and Jana Kosecka and Jitendra Malik and Roozbeh Mottaghi and Manolis Savva and Amir R. Zamir},
  journal={arXiv preprint arXiv:1807.06757},
  year={2018},
  month={July}
}

Directed graph exploration is extremely hard.
@article{foerster:tcs16,
title = "Lower and upper competitive bounds for online directed graph exploration",
author = "Klaus-Tycho Foerster and Roger Wattenhofer",
year = "2016",
month = "December",
volume = "655A",
pages = "15--29",
journal = "Theoretical Computer Science",
publisher = "Elsevier",
}

An interactive environment to accomplish natural language instructions like ``Put the cereal, the sponge, and the dishwashing soap into the cupboard above the sink'' that require navigation and action; their proposed model uses reinforcement learning techniques to explore the space of actions, but the baseline decouples goal prediction and action generation to allow different training paradigms for each.
@InProceedings{misra:emnlp18,
  author =  "Dipendra Misra and Andrew Bennett and Valts Blukis and Eyvind Niklasson and Max Shatkhin
    and Artzi, Yoav",
  title =   "Mapping Instructions to Actions in {3D} Environments with Visual Goal Prediction",
  booktitle =   "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
  year =  "2018",
  publisher =   "Association for Computational Linguistics",
  location =  "Brussels, Belgium"
}

@inproceedings{chen:aaai11,
  title={Learning to Interpret Natural Language Navigation Instructions from Observations},
  author={David L. Chen and Raymond J. Mooney},
  booktitle={AAAI},
  year={2011}
}

@inproceedings{hu:iccv17,
  title={Learning to Reason: End-to-End Module Networks for Visual Question Answering},
  author={Hu, Ronghang and Andreas, Jacob and Rohrbach, Marcus and Darrell, Trevor and Saenko, Kate},
  booktitle={ICCV},
  year={2017},
}

@inproceedings{fried:nips18,
  title={Speaker-Follower Models for Vision-and-Language Navigation},
  author={Fried, Daniel and Hu, Ronghang and Cirik, Volkan and Rohrbach, Anna and Andreas, Jacob and Morency, Louis-Philippe and Berg-Kirkpatrick, Taylor and Saenko, Kate and Klein, Dan and Darrell, Trevor},
  booktitle={Neural Information Processing Systems (NeurIPS)},
  year={2018}
}

@inproceedings{guadarrama:iros13, 
  author={S. Guadarrama and L. Riano and D. Golland and D. Go¨hring and Y. Jia and D. Klein and P. Abbeel and T. Darrell}, 
  booktitle={2013 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={Grounding spatial relations for human-robot interaction}, 
  year={2013}, 
  pages={1640-1647} 
}

@inproceedings{chai:ijcai18,
 author = {Joyce Y. Chai and Qiaozi Gao and Lanbo She and Shaohua Yang and Sari Saba-Sadiya and Guangyue Xu},
 title = {Language to Action: Towards Interactive Task Learning with Physical Agents},
 booktitle = {IJCAI},
 year = {2018},
} 

Pipeline for context-aware image-captioning that first generates template-based captions with fills like <Athlete>, <Location>, and <Organization>, then instantiates entities into those slots by searching social media using hashtags associated with the original image for neighboring images and using their captions as textual context to find possible entity instances.
Throws away vision information during entity instantiation, relying instead of co-occurrence in extracted relevant text from neighboring image captions (which are again based just on hashtags, not image features). Relies on a lot of pipeline steps from different black box algorithms.
@inproceedings{lu:emnlp18,
 author={Di Lu and Spencer Whitehead and Lifu Huang and Heng Ji and Shih-Fu Chang},
 title={Entity-aware Image Caption Generation},
 booktitle={Proceedings of the Conference on Emperical Methods in Natural Language Processing (EMNLP-18)},
 year={2018},
}

Replaces hard parsing as a preprocessing step in building a modular referring expression understanding network with a soft attention mechanism. Hand-code different kinds of features to feed to a subject, location, and relationship visual network to drive them towards attending to words in the expression related to particular kinds of information (color/shape/size, spatial relations, and relationships to other objects, respectively). In the end, used to score bounding boxes from among options given input images, bounding boxes, and referring expression. Achieves improvements over previous state of the art, but hand-engineered features don't buy a huge gain over just subbing out ResNet for VGG on general pipeline.
@inproceedings{yu:cvpr18,
 author={Licheng Yu and Zhe Lin and Xiaohui Shen and Jimei Yang and Xin Lu and Mohit Bansal and Tamara Berg},
 title={MAttNet: Modular Attention Network for Referring Expression Comprehension},
 booktitle={Proceedings of the Conference on Computer Vision and Pattern Recognition (CVPR-18)},
 year={2018},
}

End-to-end pipeline for translating natural language commands to quadcopter control in simulated environment. Commands are of forms like "fly towards the banana and stop on its left side". The world involves large, unocluded objects on the ground, grass terrain, and water terrain. The language is human generated but necessarily somewhat simple (but not template simple). The "API" is that the model first translates language into a predicted distribution over places to visit + a place to stop, then refines those predictions as more of the world is seen (inference is performed every few timesteps, as far as I can tell, but explicitly not continuously). This stage is supervised with gold standard trajectories given by human demonstrators. Language descriptions and trajectory demonstrations come from an existing dataset from Valts. The second stage of the pipeline uses imitation learning in the simulator to take the distributions as input and produce motor control to satisfy visitation constraints and stopping criteria. In the end, they don't evaluate against whether they match the path constraints towards the trajectory, just whether they reach the correct destination, which is weird since they try to model the path along the way and the language specifies path constraints sometimes.
@InProceedings{blukis:corl18,
  author = "Valts Blukis and Dipendra Misra and Ross A. Knepper and Yoav Artzi",
  title = "Mapping Navigation Instructions to Continuous Control Actions with Position Visitation Prediction",
  booktitle = "CoRL",
  year = "2018",
}

Straightforward discussion of conditioning GANs on additional information. Upshot: just feed conditional information into generator and discriminator along with noise distribution by concatenating as additional input. Paper doesn’t make a big fuss about how to process this information further (they use simple ReLU layers and MLPs for MNIST + Flickr images).
@article{mirza:arxiv14,
  title={Conditional generative adversarial nets},
  author={Mirza, Mehdi and Osindero, Simon},
  journal={arXiv preprint arXiv:1411.1784},
  year={2014}
}

More conditional GANs, this time conditioning the generation of bird and flower images on captions. Text representation "visually-discriminative vector representation...that learns a correspondence function with images" from prior work I'm not familiar with. Seems like some of the gains/power might come from text already being tied strongly to image features being extracted, though, which is non-trivial and, like, sensible. Core ideas are similar to mirza:arxiv14 but executed more convincingly and with a few extra tricks, e.g.: Matching-aware discriminator (discriminator loss explicitly rewared for figuring out fake image versus fake caption / real image paired with wrong caption); Learning with manifold interpolation (data augmentation by interpolating between pairs of embedded captions to get embeddings near the data manifold that don't correspond to real captions/images anyway (not sure how this is used in training from a first pass though)). They follow up with some qualitative looks at style transfer (where style is non-caption content like background and 'iconographic sense'), which is facilitated with birds data by clustering on background color and bird pose points that are given as part of the data (beak, head, etc. positions). In general this makes it seem not too impossible to do image generation given enough patience and resources.
@inproceedings{reed:icml16,
  title={Generative Adversarial Text to Image Synthesis},
  author={Scott Reed and Zeynep Akata and Xinchen Yan and Lajanugen Logeswaran and Bernt Schiele and Honglak Lee},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2016}
}

Conditional GAN with layers. The first layer generates a blurry, low-resolution image from an entire language description encoded into one vector (more like a traditional conditional GAN). Subsequent layers attend to regions of this low-resolution image jointly with individual words in the description, refining each to produce a higher-resolution image where new patches' inputs are conditioned on the previous image and a weighted attentional sum of word embeddings from the image description. In this way, the network can learn to attend to patches of the image and relevant sub-parts of the description (e.g., "beak", "red", etc.). The authors evaluate one and two layers of such attentional refinement, achieving SotA inception scores on CUB and COCO. They also propose a recall-based metric for how well generated images match text descriptions, but it's fuzzy and liberal and my intuition is that it overestimates performance. Part of the contribution of the paper is also the loss function, which is another trained network that aligns the text description and the generated image to ensure coherence. The paper notes that using out of the box word embeddings is a bonkers idea for image generation because ungrounded word embeddings don't make visual sense, which is nice to state explicitly. They instead pre-train word embeddings on the task itself with (held out?) task data.
@inproceedings{xu:cvpr18,
  author={Tao Xu and Pengchuan Zhang and Qiuyuan Huang and Han Zhang and Zhe Gan and Xiaolei Huang and Xiaodong He},
  title={AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks},
  year={2018},
  booktitle={Computer Vision and Pattern Recognition (CVPR)}
}

Use integrated gradients method to analyze question answering models (vqa, wiki tables, squad) and show that state of the art methods tend to focus on the wrong words to make predictions, instead relying on the context (image/table/paragraph) to prime the model for a small set of candidate answers, then using the question primarily to identify the type of answer to return, not actual content.
@inproceedings{mudrakarta:acl18,
  title={Did the Model Understand the Question?},
  author={Mudrakarta, Pramod Kaushik and Taly, Ankur and Sundararajan, Mukund and Dhamdhere, Kedar},
  booktitle={Conference of the Association for Computational Linguistics (ACL)},
  year={2018}
}

@inproceedings{cirik:naacl18,
  title={Visual Referring Expression Recognition: What Do Systems Actually Learn?},
  author={Volkan Cirik and Louis-Philippe Morency and Taylor Berg-Kirkpatrick},
  booktitle={Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)},
  year={2018}
}

@inproceedings{das:corl18,
  title={{N}eural {M}odular {C}ontrol for {E}mbodied {Q}uestion {A}nswering},
  author={Abhishek Das and Georgia Gkioxari and Stefan Lee and Devi Parikh and Dhruv Batra},
  booktitle={Proceedings of the Conference on Robot Learning (CoRL)},
  year={2018}
}

@article{devlin:arxiv18,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@InProceedings{maas:acl11,
  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},
  title     = {Learning Word Vectors for Sentiment Analysis},
  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},
  month     = {June},
  year      = {2011},
  address   = {Portland, Oregon, USA},
  publisher = {Association for Computational Linguistics},
  pages     = {142--150},
  url       = {http://www.aclweb.org/anthology/P11-1015}
}

@unpublished{wang:glue18,
  title={{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},
  author={Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},
  note={arXiv preprint 1804.07461},
  year={2018}
}

@inproceedings{vaswani:nips17,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}

@inproceedings{bahdanau:iclr15,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  booktitle={International Conference on Learning Representations},
  year={2015}
}

@article{wu:arxiv16,
  title={Google's neural machine translation system: Bridging the gap between human and machine translation},
  author={Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and Le, Quoc V and Norouzi, Mohammad and Macherey, Wolfgang and Krikun, Maxim and Cao, Yuan and Gao, Qin and Macherey, Klaus and others},
  journal={arXiv preprint arXiv:1609.08144},
  year={2016}
}

@inproceedings{rush:emnlp15,
  title={A neural attention model for abstractive sentence summarization},
  author={Rush, Alexander M and Chopra, Sumit and Weston, Jason},
  booktitle={Conference on Emperical Methods in Natural Language Processing},
  year={2015}
}

@inproceedings{yang:cvpr16,
  title={Stacked attention networks for image question answering},
  author={Yang, Zichao and He, Xiaodong and Gao, Jianfeng and Deng, Li and Smola, Alex},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={21--29},
  year={2016}
}

Uses template text after every N steps of planning rollout to give "correction" to agent. Suspect that text actually functions as a sort of external memory structure since the agent has no mechanism for memory between separate trajectory rollouts. Read in RoboNLP winter quarter Jan 29 (Aaron presenting).
@article{coreyes:corr18,
  author    = {John D. Co{-}Reyes and Abhishek Gupta and Suvansh Sanjeev and Nick Altieri and John DeNero and Pieter Abbeel and Sergey Levine},
  title     = {Guiding Policies with Language via Meta-Learning},
  journal   = {CoRR},
  volume    = {abs/1811.07882},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.07882}
}

R2R approach that briefly set SotA by adding joint textual-visual grounding and a "progress monitor" module that predicted a normalized distance in (-inf, 1] to the goal, with 0 representing the starting point distance. Might serve as a good base / inspiration model for action reps.
@inproceedings{ma:iclr19,
  title={Self-Monitoring Navigation Agent via Auxiliary Progress Estimation},
  author={Ma, Chih-Yao and Lu, Jiasen and Wu, Zuxuan and AlRegib, Ghassan and Kira, Zsolt and Socher, Richard and Xiong, Caiming},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{skoviera:iros18,
  title={Teaching robots to imitate a human with no on-teacher sensors. What are the key challenges?},
  author={Skoviera, Radoslav and Stepanova, Karla and Tesar, Michael and Sejnova, Gabriela and Sedlar, Jiri and Vavrecka, Michal and Babuska, Robert and Sivic, Josef},
  booktitle={International Conference on Intelligent Robots and Systems (IROS) Workshop on Towards Intelligent Social Robots: From Naive Robots to Robot Sapiens},
  year={2018}
}

@inproceedings{shah:icra18,
  title={Follownet: Robot navigation by following natural language directions with deep reinforcement learning},
  author={Shah, Pararth and Fiser, Marek and Faust, Aleksandra and Kew, J Chase and Hakkani-Tur, Dilek},
  booktitle={International Conference on Robotics and Automation (ICRA) Third Workshop in Machine Learning in the Planning and Control of Robot Motion},
  year={2018}
}

@inproceedings{bisk:aaai18,
  title={Learning interpretable spatial operations in a rich 3d blocks world},
  author={Bisk, Yonatan and Shih, Kevin J and Choi, Yejin and Marcu, Daniel},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@inproceedings{yang:corl18,
  title={Visual Curiosity: Learning to Ask Questions to Learn Visual Recognition},
  author={Yang, Jianwei and Lu, Jiasen and Lee, Stefan and Batra, Dhruv and Parikh, Devi},
  booktitle={Conference on Robot Learning (CoRL)},
  year={2018}
}

@InProceedings{nyga:corl18,
  title =    {Grounding Robot Plans from Natural Language Instructions with Incomplete World Knowledge},
  author =   {Nyga, Daniel and Roy, Subhro and Paul, Rohan and Park, Daehyung and Pomarlan, Mihai and Beetz, Michael and Roy, Nicholas},
  booktitle =    {Conference on Robot Learning (CoRL)},
  year =   {2018}
}

@inproceedings{vanzo:aamas18,
 author = {Vanzo, Andrea and Part, Jose L. and Yu, Yanchao and Nardi, Daniele and Lemon, Oliver},
 title = {Incrementally Learning Semantic Attributes Through Dialogue Interaction},
 booktitle = {Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems},
 year = {2018}
} 

@InProceedings{wang:eccv18,
author = {Wang, Xin and Xiong, Wenhan and Wang, Hongmin and Yang Wang, William},
title = {Look Before You Leap: Bridging Model-Free and Model-Based Reinforcement Learning for Planned-Ahead Vision-and-Language Navigation},
booktitle = {The European Conference on Computer Vision (ECCV)},
year = {2018}
}

@inproceedings{pillai:aaai18,
  title={Unsupervised selection of negative examples for grounded language learning},
  author={Pillai, Nisha and Matuszek, Cynthia},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@inproceedings{kingma:iclr15,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  booktitle={International Conference on Learning Representations},
  year={2015}
}

@inproceedings{levesque:aaai2011,
  title={The Winograd Schema Challenge},
  author={Hector J. Levesque},
  booktitle={AAAI Spring Symposium: Logical Formalizations of Commonsense Reasoning},
  year={2011}
}

@inproceedings{iberall:icra88,
  title={Knowledge-based prehension: Capturing human dexterity},
  author={Iberall, Thea and Jackson, Joe and Labbe, Liz and Zampano, Ralph},
  booktitle={IEEE International Conference on Robotics and Automation},
  organization={IEEE}
}

@inproceedings{knepper:icra13,
  title={Ikeabot: An autonomous multi-robot coordinated furniture assembly system},
  author={Knepper, Ross A and Layton, Todd and Romanishin, John and Rus, Daniela},
  booktitle={2013 IEEE International Conference on Robotics and Automation},
  year={2013},
}

@inproceedings{suarez:icra16,
  author = {Su\'{a}rez{-}Ruiz, Francisco and Pham, Quang{-}Cuong},
  booktitle = {IEEE International Conference on Robotics and Automation},
  title = {A Framework for Fine Robotic Assembly},
  year = {2016},
}

@article{kyrarini:auro19,
  title={Robot learning of industrial assembly task via human demonstrations},
  author={Kyrarini, Maria and Haseeb, Muhammad Abdul and Risti{\'c}-Durrant, Danijela and Gr{\"a}ser, Axel},
  journal={Autonomous Robots},
  volume={43},
  number={1},
  pages={239--257},
  year={2019},
  publisher={Springer}
}

@inproceedings{mahler:icra16,
  title={Dex-net 1.0: A cloud-based network of 3d objects for robust grasp planning using a multi-armed bandit model with correlated rewards},
  author={Mahler, Jeffrey and Pokorny, Florian T and Hou, Brian and Roderick, Melrose and Laskey, Michael and Aubry, Mathieu and Kohlhoff, Kai and Kr{\"o}ger, Torsten and Kuffner, James and Goldberg, Ken},
  booktitle={IEEE International Conference on Robotics and Automation},
  year={2016},
}

@inproceedings{jayaraman:iccv15,
  author = {D. Jayaraman and K. Grauman},
  title = {{Learning image representations tied to egomotion}},
  booktitle = {ICCV},
  year = {2015}
}

@article{duckworth:ai19,
  title={Unsupervised human activity analysis for intelligent mobile robots},
  author={Duckworth, Paul and Hogg, David C and Cohn, Anthony G},
  journal={Artificial Intelligence},
  volume={270},
  pages={67--92},
  year={2019},
}

@book{bordwell:film03,
    title = {Film Art: An Introduction},
    author = {David Bordwell and Kristin Thompson},
    isbn = {9780072484557},
    edition = {7},
    year = {2003},
    publisher = {McGraw-Hill Companies},
}

Introduces a dialog-esque approach in Matterport termed Vision-based Navigation with Language-based Assistance (VNLA).
Commands are given via templated "find an [X] in the [Y]" for X objects and Y locations.
An agent explores the environment and can request assistance, which is provided by an Advisor that can query the gold shortest-path to the destination, and converts the next k steps along that path into a templated language instruction.
The paper also presents a model for processing commands, assistance clarifications, and performing navigation and help request decisions in an end-to-end trainable fashion.
@inproceedings{nguyen:cvpr19,
  title={Vision-based Navigation with Language-based Assistance via Imitation Learning with Indirect Intervention},
  author={Nguyen, Khanh and Dey, Debadeepta and Brockett, Chris and Dolan, Bill},
  booktitle={CVPR},
  year={2019}
}

@inproceedings{taylor2011integrating,
  title={Integrating reinforcement learning with human demonstrations of varying ability},
  author={Taylor, Matthew E and Suay, Halit Bener and Chernova, Sonia},
  booktitle={AAMAS},
  year={2011},
}

@inproceedings{wang2017improving,
  title={Improving Reinforcement Learning with Confidence-Based Demonstrations.},
  author={Wang, Zhaodong and Taylor, Matthew E},
  booktitle={IJCAI},
  year={2017}
}